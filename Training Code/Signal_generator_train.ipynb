{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.keras import layers\n",
    "#from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM,Dropout,Conv2D,TimeDistributed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, LSTM, TimeDistributed, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import (Conv2D, TimeDistributed, MaxPooling2D,\n",
    "                                     MaxPooling3D, AveragePooling2D, Conv2DTranspose, UpSampling2D,\n",
    "                                     BatchNormalization,\n",
    "                                     Dense, Flatten, Reshape,Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramp_classifier_output(labels,n=10):\n",
    "    ramp_out=np.zeros((labels.shape[0],32,n))\n",
    "    ramp=np.linspace(0,2,32)\n",
    "\n",
    "    for i in range(labels.shape[0]):\n",
    "        ramp_out[i,:,int(labels[i])]=ramp\n",
    "    return ramp_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_output(labels,n=10):\n",
    "    cross_entropy_out=np.zeros((labels.shape[0],32,n))\n",
    "    ce=np.ones(32)\n",
    "\n",
    "    for i in range(labels.shape[0]):\n",
    "        cross_entropy_out[i,:,int(labels[i])]=ce\n",
    "    return cross_entropy_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def cross_entropy_output_tf(labels, n=10):\n",
    "    # Create a tensor of zeros with the desired shape\n",
    "    cross_entropy_out = tf.zeros((tf.shape(labels)[0], 32, n), dtype=tf.float32)\n",
    "    \n",
    "    # Create a tensor of ones with shape (32,) (equivalent to np.ones(32))\n",
    "    ce = tf.ones((32,), dtype=tf.float32)\n",
    "\n",
    "    # Loop through each label and set the cross-entropy output\n",
    "    for i in range(tf.shape(labels)[0]):\n",
    "        cross_entropy_out = cross_entropy_out[i].assign(tf.tensor_scatter_nd_update(\n",
    "            cross_entropy_out[i], [[i, int(labels[i])]], [ce]))\n",
    "\n",
    "    return cross_entropy_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def cross_entropy_output_tf(labels, n=10):\n",
    "    # Create a tensor of zeros with the desired shape\n",
    "    cross_entropy_out = tf.zeros((tf.shape(labels)[0], 32, n), dtype=tf.float32)\n",
    "\n",
    "    # Create a tensor of ones with shape (32,) (equivalent to np.ones(32))\n",
    "    ce = tf.ones((32,), dtype=tf.float32)\n",
    "\n",
    "    # Create indices for where to place the ones\n",
    "    indices = []\n",
    "    updates = []\n",
    "\n",
    "    for i in range(tf.shape(labels)[0]):\n",
    "        indices.append([i, int(labels[i])])  # Append the indices where ones should be placed\n",
    "        updates.append(ce)  # Append the values to be placed\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    indices = tf.convert_to_tensor(indices, dtype=tf.int32)\n",
    "    updates = tf.convert_to_tensor(updates, dtype=tf.float32)\n",
    "\n",
    "    # Use tensor_scatter_nd_update to place ones at the desired positions\n",
    "    cross_entropy_out = tf.tensor_scatter_nd_update(cross_entropy_out, indices, updates)\n",
    "\n",
    "    return cross_entropy_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load('X_trn_img.npy')\n",
    "X_test=np.load('X_test_img.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32, 20, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[X_test[10*i] for i in range(0, int(X_test.shape[0]/10))]\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 32, 20, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_img=[]\n",
    "for i in range(100):\n",
    "    for j in range(54):\n",
    "        X_test_img.append(X_test[i])\n",
    "X_test_img=np.array(X_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_test_img_5400.npy\",X_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 32, 20, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26852fc9250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test_img[5050][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 14, 1)\n",
      "(40000, 32, 14)\n",
      "(40000, 32)\n",
      "(5400, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'eeg_data_normalized = np.zeros_like(eeg_data)\\n\\nfor i in range(eeg_data.shape[0]):\\n    eeg_data_normalized[i, :] = scaler.fit_transform(eeg_data[i, :].reshape(-1, 1)).reshape(-1)\\n\\n\\nprint(eeg_data_normalized.shape)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=np.load('X_eeg_train.npy')\n",
    "y_test=np.load('X_eeg_test.npy')\n",
    "y_test=np.load(\"../data_for_ogan/X_eeg_test.npy\")\n",
    "\n",
    "y_train = np.moveaxis(y_train, 1, 2)\n",
    "y_test=np.moveaxis(y_test,1,2)\n",
    "print(y_train.shape)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "y_train = scaler.fit_transform(y_train.reshape(-1, y_train.shape[-1])).reshape(y_train.shape)\n",
    "y_test = scaler.fit_transform(y_test.reshape(-1, y_test.shape[-1])).reshape(y_test.shape)\n",
    "\n",
    "squeezed_data = np.squeeze(y_train, axis=-1)\n",
    "squeezed_data1 = np.squeeze(y_test, axis=-1)\n",
    "\n",
    "print(squeezed_data.shape)\n",
    "#eeg_data= squeezed_data\n",
    "main_EEG = squeezed_data[:, :, 6]  # 6 ,7 o1,o2\n",
    "print(main_EEG.shape)\n",
    "y_train1=main_EEG\n",
    "y_test1=squeezed_data1[:,:,6]\n",
    "y_train1=np.expand_dims(y_train1,axis=-1)\n",
    "y_test1=np.expand_dims(y_test1,axis=-1)\n",
    "print(y_test1.shape)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"eeg_data_normalized = np.zeros_like(eeg_data)\n",
    "\n",
    "for i in range(eeg_data.shape[0]):\n",
    "    eeg_data_normalized[i, :] = scaler.fit_transform(eeg_data[i, :].reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "\n",
    "print(eeg_data_normalized.shape)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"y_test_classify=np.load('Y_test_labels.npy')\\ny_train_labels_filtered=y_train\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_labels=np.load('Y_train_labels.npy')\n",
    "\"\"\"y_test_classify=np.load('Y_test_labels.npy')\n",
    "y_train_labels_filtered=y_train\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels=np.load(\"../data_for_ogan/Y_test_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(540.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_labels[540:1080].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_classify=ramp_classifier_output(y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_classify.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_signals=np.load(\"../data_for_ogan/X_eeg_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_classify=ramp_classifier_output(y_train_labels,n=10)\n",
    "#y_test_classify=ramp_classifier_output(y_test_labels,n=10)\n",
    "\n",
    "#y_train_gen=ramp_classifier_output(9*np.ones(100),n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_classify_ce=cross_entropy_output(y_train_labels,n=10)\n",
    "#y_test_classify_ce=cross_entropy_output(y_test_labels,n=10)\n",
    "\n",
    "#y_train_gen_ce=cross_entropy_output(9*np.ones(100),n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train = X_train.reshape(X_train.shape[0], 32, 400)\\nX_test = X_test.reshape(X_test.shape[0], 32, 400)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_train = X_train.reshape(X_train.shape[0], 32, 400)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 400)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all=np.squeeze(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 32, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional helper data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_autoencoder=X_autoencoder.reshape(X_autoencoder.shape[0], 32, 400)\n",
    "\n",
    "X_autoencoder=[]\n",
    "import cv2\n",
    "letters=['A','C','F','H','J','M','P','S','T','Y']\n",
    "letters_small=['a','c','f','h','j','m','p','s','t','y']\n",
    "\n",
    "root_folder='../data_for_OGAN/images/'\n",
    "for i in range(len(letters)):\n",
    "    curr_folder=f'{root_folder}{letters[i]}/{letters_small[i]} ('\n",
    "    for j in range(20):\n",
    "        img_path=f'{curr_folder}{j+1}).png'\n",
    "        #print(img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        #print(image)\n",
    "        resized_image = cv2.resize(image, (20, 20))\n",
    "        gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "        X_autoencoder.append(np.stack([gray_image] * 32, axis=0))\n",
    "\n",
    "\n",
    "X_autoencoder=np.array(X_autoencoder)\n",
    "X_autoencoder=X_autoencoder.reshape(X_autoencoder.shape[0], 32, 400)\n",
    "y_autoencoder=[0 for i in range(20)]+[1 for i in range(20)]+[2 for i in range(20)]+[3 for i in range(20)]+[4 for i in range(20)]+[5 for i in range(20)]+[6 for i in range(20)]+[7 for i in range(20)]+[8 for i in range(20)]+[9 for i in range(20)]\n",
    "\n",
    "y_autoencoder=np.array(y_autoencoder)\n",
    "y_autoencoder=ramp_classifier_output(y_autoencoder,n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_classifier\n",
    "@tf.function\n",
    "def real_cal(r, phi):\n",
    "    return r * tf.math.cos(phi)\n",
    "\n",
    "@tf.function\n",
    "def imag_cal(r, phi):\n",
    "    return r * tf.math.sin(phi)\n",
    "\n",
    "@tf.function\n",
    "def oscillator_loop(X_r, X_i, omegas, num_steps):\n",
    "    # batch_size x timesteps X dim\n",
    "    r_arr = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True) # creates empty array to save r_t\n",
    "    phi_arr = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    r_t = tf.ones((tf.shape(X_r)[0], tf.shape(X_r)[-1])) # Initializing r_t\n",
    "    phis = tf.zeros((tf.shape(X_r)[0], tf.shape(X_r)[-1])) # Initislizing phi_t\n",
    "    dt = 1/128\n",
    "    input_scaler = 2\n",
    "    beta=1\n",
    "\n",
    "    for t in tf.range(num_steps):\n",
    "        input_r = input_scaler*X_r[:,t,:]*tf.math.cos(phis)\n",
    "        input_phi = input_scaler*X_i[:,t,:]*tf.math.sin(phis)\n",
    "        r_t = r_t + ((1 - beta*tf.square(r_t)) * r_t + input_r) * dt\n",
    "        phis = phis + (omegas - input_phi) * dt\n",
    "        r_arr = r_arr.write(r_arr.size(), r_t)  #1000,1,2\n",
    "        phi_arr = phi_arr.write(phi_arr.size(), phis)\n",
    "    r_arr = tf.transpose(r_arr.stack(), [1, 0, 2])  # Changing dimensions to 1,1000,2\n",
    "    phi_arr = tf.transpose(phi_arr.stack(), [1, 0, 2])\n",
    "    return r_arr, phi_arr\n",
    "\n",
    "class Hopf(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, num_steps, min_omega=0.1,\n",
    "                 max_omega=64.1,train_omegas=True, **kwargs):\n",
    "        super(Hopf, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.num_steps = num_steps\n",
    "        self.train_omegas=train_omegas\n",
    "        self.max_omega=max_omega\n",
    "        self.min_omega=min_omega\n",
    "        # self.omegas = tf.linspace(min_omega, max_omega, self.units) * (2*3.1415)\n",
    "        # self.omegas = tf.cast(tf.expand_dims(self.omegas, 0), 'float32')\n",
    "\n",
    "        omega_init=tf.random.uniform((1,self.units),-1,1)\n",
    "        self.omegas=tf.Variable(omega_init,trainable=self.train_omegas)\n",
    "\n",
    "    def call(self, X_r, X_i):\n",
    "        omega_intl = self.max_omega - self.min_omega\n",
    "        omega_inp = tf.sigmoid(0.5*self.omegas) * omega_intl + self.min_omega\n",
    "\n",
    "\n",
    "        r, phi = oscillator_loop(X_r, X_i, omega_inp , self.num_steps)\n",
    "        z_real = real_cal(r, phi)\n",
    "        z_imag = imag_cal(r, phi)\n",
    "        return z_real, z_imag\n",
    "\n",
    "\n",
    "duration = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_classifier(tf.keras.Model):\n",
    "    def __init__(self, units1, units2,units21,units22,units23, units3,units4,  units5, units7, units6,  **kwargs):\n",
    "        super(Model_classifier, self).__init__(**kwargs)\n",
    "\n",
    "        self.d1=tf.keras.layers.Dense(units1, activation='relu')  # 250\n",
    "        self.d2=tf.keras.layers.Dense(units2, activation='relu')  #200\n",
    "        self.d21=tf.keras.layers.Dense(units21, activation='relu')  #150\n",
    "        self.d22=tf.keras.layers.Dense(units22, activation='relu')  #100\n",
    "        self.d23=tf.keras.layers.Dense(units23, activation='relu')  #50\n",
    "\n",
    "\n",
    "        self.d3_r=tf.keras.layers.Dense(units3, activation='relu')\n",
    "        self.d3_i=tf.keras.layers.Dense(units3, activation='relu')\n",
    "        self.osc1=Hopf(units4, num_steps=duration, min_omega=0.1, max_omega=64.1, train_omegas=True)\n",
    "\n",
    "        #self.d3_r1=tf.keras.layers.Dense(units9, activation='relu')\n",
    "        #self.d3_i1=tf.keras.layers.Dense(units9, activation='relu')\n",
    "        #self.osc2=Hopf(units10, num_steps=duration, min_omega=0.1, max_omega=64.1, train_omegas=True)\n",
    "\n",
    "        self.d4_r=tf.keras.layers.Dense(units5, activation='tanh')\n",
    "        self.d4_i=tf.keras.layers.Dense(units5, activation='tanh')\n",
    "\n",
    "        self.d5=tf.keras.layers.Dense(units7, activation='tanh')\n",
    "        #self.d6=tf.keras.layers.Dense(units8, activation='tanh')\n",
    "\n",
    "        #self.d5_i=tf.keras.layers.Dense(units7, activation='tanh')\n",
    "        self.out_dense=tf.keras.layers.Dense(units6, activation='linear')\n",
    "    \n",
    "    def call(self, X):\n",
    "        out1=tf.keras.layers.TimeDistributed(self.d1)(X)    #250\n",
    "        out2=tf.keras.layers.TimeDistributed(self.d2)(out1) #200\n",
    "        out21=tf.keras.layers.TimeDistributed(self.d21)(out2) #150\n",
    "        out22=tf.keras.layers.TimeDistributed(self.d22)(out21) #100\n",
    "        out23=tf.keras.layers.TimeDistributed(self.d23)(out22) #50\n",
    "\n",
    "\n",
    "        out3_r=tf.keras.layers.TimeDistributed(self.d3_r)(out23) #25\n",
    "        out3_i=tf.keras.layers.TimeDistributed(self.d3_i)(out23)\n",
    "        z1_r, z1_i = self.osc1(out3_r, out3_i)\n",
    "\n",
    "        #out3_r1=tf.keras.layers.TimeDistributed(self.d3_r1)(z1_r)\n",
    "        #out3_i1=tf.keras.layers.TimeDistributed(self.d3_i1)(z1_i)\n",
    "        #z1_r1, z1_i1 = self.osc2(out3_r1, out3_i1)\n",
    "\n",
    "        out4_r=tf.keras.layers.TimeDistributed(self.d4_r)(z1_r)\n",
    "        out4_i=tf.keras.layers.TimeDistributed(self.d4_i)(z1_i)\n",
    "        concat_inp=tf.concat([out4_r,out4_i],2)\n",
    "        out5=tf.keras.layers.TimeDistributed(self.d5)(concat_inp)\n",
    "        #out6=tf.keras.layers.TimeDistributed(self.d6)(out5)\n",
    "\n",
    "\n",
    "        out_final=tf.keras.layers.TimeDistributed(self.out_dense)(out5)\n",
    "\n",
    "        return out_final\n",
    "        #return [out3_r,out3_i]\n",
    "\n",
    "model_classifier =  Model_classifier(250, 200,150,100, 50,25, 25,20, 15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_classifier2(tf.keras.Model):\n",
    "    def __init__(self, units1, units2,units21,units22,units23, units3,units4,  units5, units7, units6,  **kwargs):\n",
    "        super(Model_classifier2, self).__init__(**kwargs)\n",
    "\n",
    "        self.d1=tf.keras.layers.Dense(units1, activation='relu')  # 250\n",
    "        self.d2=tf.keras.layers.Dense(units2, activation='relu')  #200\n",
    "        self.d21=tf.keras.layers.Dense(units21, activation='relu')  #150\n",
    "        self.d22=tf.keras.layers.Dense(units22, activation='relu')  #100\n",
    "        self.d23=tf.keras.layers.Dense(units23, activation='relu')  #50\n",
    "\n",
    "\n",
    "        self.d3_r=tf.keras.layers.Dense(units3, activation='relu')\n",
    "        self.d3_i=tf.keras.layers.Dense(units3, activation='relu')\n",
    "        self.osc1=Hopf(units4, num_steps=duration, min_omega=0.1, max_omega=64.1, train_omegas=True)\n",
    "\n",
    "        #self.d3_r1=tf.keras.layers.Dense(units9, activation='relu')\n",
    "        #self.d3_i1=tf.keras.layers.Dense(units9, activation='relu')\n",
    "        #self.osc2=Hopf(units10, num_steps=duration, min_omega=0.1, max_omega=64.1, train_omegas=True)\n",
    "\n",
    "        self.d4_r=tf.keras.layers.Dense(units5, activation='tanh')\n",
    "        self.d4_i=tf.keras.layers.Dense(units5, activation='tanh')\n",
    "\n",
    "        self.d5=tf.keras.layers.Dense(units7, activation='tanh')\n",
    "        #self.d6=tf.keras.layers.Dense(units8, activation='tanh')\n",
    "\n",
    "        #self.d5_i=tf.keras.layers.Dense(units7, activation='tanh')\n",
    "        self.out_dense=tf.keras.layers.Dense(units6, activation='linear')\n",
    "    \n",
    "    def call(self, X):\n",
    "        out1=tf.keras.layers.TimeDistributed(self.d1)(X)    #250\n",
    "        out2=tf.keras.layers.TimeDistributed(self.d2)(out1) #200\n",
    "        out21=tf.keras.layers.TimeDistributed(self.d21)(out2) #150\n",
    "        out22=tf.keras.layers.TimeDistributed(self.d22)(out21) #100\n",
    "        out23=tf.keras.layers.TimeDistributed(self.d23)(out22) #50\n",
    "\n",
    "\n",
    "        out3_r=tf.keras.layers.TimeDistributed(self.d3_r)(out23) #25\n",
    "        out3_i=tf.keras.layers.TimeDistributed(self.d3_i)(out23)\n",
    "        z1_r, z1_i = self.osc1(out3_r, out3_i)\n",
    "\n",
    "        #out3_r1=tf.keras.layers.TimeDistributed(self.d3_r1)(z1_r)\n",
    "        #out3_i1=tf.keras.layers.TimeDistributed(self.d3_i1)(z1_i)\n",
    "        #z1_r1, z1_i1 = self.osc2(out3_r1, out3_i1)\n",
    "\n",
    "        out4_r=tf.keras.layers.TimeDistributed(self.d4_r)(z1_r)\n",
    "        out4_i=tf.keras.layers.TimeDistributed(self.d4_i)(z1_i)\n",
    "        concat_inp=tf.concat([out4_r,out4_i],2)\n",
    "        out5=tf.keras.layers.TimeDistributed(self.d5)(concat_inp)\n",
    "        #out6=tf.keras.layers.TimeDistributed(self.d6)(out5)\n",
    "\n",
    "\n",
    "        out_final=tf.keras.layers.TimeDistributed(self.out_dense)(out5)\n",
    "\n",
    "        return [out3_r, out3_i]\n",
    "        #return [out3_r,out3_i]\n",
    "\n",
    "model_classifier2 =  Model_classifier2(250, 200,150,100, 50,25, 25,20, 15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model_classifier.compile(optimizer, 'mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model_classifier.load_weights('oscillator_classifier_high_net3.h5')\\nmodel_classifier.osc1.omegas=tf.constant(np.load('trained_omegas_classifier_high_net3.npy'))\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=model_classifier(np.random.uniform(0,1,(1,32,400)))\n",
    "\"\"\"model_classifier.load_weights('oscillator_classifier_high_net3.h5')\n",
    "model_classifier.osc1.omegas=tf.constant(np.load('trained_omegas_classifier_high_net3.npy'))\"\"\"\n",
    "#history_classifier = model_classifier.fit(X_train/255, y_train_classify/8, epochs=300, batch_size=1000,shuffle=True,validation_split=0)\n",
    "#model_classifier.osc2.omegas=tf.constant(np.load('10_class_data/omega2_GAN.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=model_classifier2(np.random.uniform(0,1,(1,32,400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['time_distributed']>\n",
      "<KeysViewHDF5 ['time_distributed_1']>\n",
      "<KeysViewHDF5 ['time_distributed_2']>\n",
      "<KeysViewHDF5 ['time_distributed_3']>\n",
      "<KeysViewHDF5 ['time_distributed_4']>\n",
      "<KeysViewHDF5 ['time_distributed_5']>\n",
      "<KeysViewHDF5 ['time_distributed_6']>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "\n",
    "# Path to your h5 file\n",
    "h5_file_path = 'oscillator_classifier_high_net3.h5'\n",
    "\n",
    "# Open the h5 file in read mode\n",
    "with h5py.File(h5_file_path, 'r') as h5_file:\n",
    "    weights_dict=dict(h5_file)\n",
    "    layers=list(weights_dict.keys())\n",
    "    time_distributed_layers=[\"time_distributed\"]\n",
    "    time_distributed_layers1=[f\"time_distributed_{i}\" for i in range(1,7)]\n",
    "    time_distributed_layers+=time_distributed_layers1\n",
    "    # Load weights for each layer\n",
    "    for i in range(7):\n",
    "        # Get the layer name from the h5 file\n",
    "        layer_name = layers[i]  # Assuming layers are in order\n",
    "        \n",
    "        weight_data=[]\n",
    "        print(dict(h5_file)[layer_name]['model_classifier2_2'].keys())\n",
    "        \n",
    "        weight_data.append(dict(h5_file)[layer_name]['model_classifier2_2'][time_distributed_layers[i]][\"kernel:0\"])\n",
    "        weight_data.append(dict(h5_file)[layer_name]['model_classifier2_2'][time_distributed_layers[i]][\"bias:0\"])\n",
    "        model_classifier2.layers[i].set_weights(weight_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model_classifier2(np.random.uniform(0,1,(1,32,400)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(7):\\n    model_classifier2.layers[i].set_weights(model_classifier.layers[i].get_weights())\\n    model_classifier2.layers[i].trainable=False\\n\\n\\nmodel_classifier2.osc1.omegas=tf.constant(model_classifier.osc1.omegas.numpy().copy())'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for i in range(7):\n",
    "    model_classifier2.layers[i].set_weights(model_classifier.layers[i].get_weights())\n",
    "    model_classifier2.layers[i].trainable=False\n",
    "\n",
    "\n",
    "model_classifier2.osc1.omegas=tf.constant(model_classifier.osc1.omegas.numpy().copy())\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train_compressed=np.load(\"10_class_data/img_compressed.npy\")\\nX_test_compressed=np.load(\"10_class_data/img_compressed_test.npy\")'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_train_compressed=model_classifier2(X_train/255)\n",
    "X_train_compressed=np.array(X_train_compressed)\"\"\"\n",
    "\n",
    "\"\"\"X_train_compressed=np.load(\"10_class_data/img_compressed.npy\")\n",
    "X_test_compressed=np.load(\"10_class_data/img_compressed_test.npy\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_test_compressed=model_classifier2(X_test/255)\\nX_test_compressed=np.array(y_test_compressed)'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_test_compressed=model_classifier2(X_test/255)\n",
    "X_test_compressed=np.array(y_test_compressed)\"\"\"\n",
    "#np.save(\"10_class_data/img_compressed_test.npy\",y_test_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2680547ea50>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_autoencoder[0,0,:].reshape(20,20),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"latent_reps=np.array(model_classifier2(X_autoencoder/255))\\nfig,axs=plt.subplots(10,20,figsize=(400,200))\\nk=0\\nprint(latent_reps.shape)\\nfor i in range(10):\\n    print(i+1)\\n    for j in range(20):\\n        #print(latent_reps[k,0,:].max(),latent_reps[k,0,:].min())\\n        axs[i][j].imshow(latent_reps[1,k,0,:].reshape(5,5),cmap='gray')\\n        k+=1\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"latent_reps=np.array(model_classifier2(X_autoencoder/255))\n",
    "fig,axs=plt.subplots(10,20,figsize=(400,200))\n",
    "k=0\n",
    "print(latent_reps.shape)\n",
    "for i in range(10):\n",
    "    print(i+1)\n",
    "    for j in range(20):\n",
    "        #print(latent_reps[k,0,:].max(),latent_reps[k,0,:].min())\n",
    "        axs[i][j].imshow(latent_reps[1,k,0,:].reshape(5,5),cmap='gray')\n",
    "        k+=1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_compressed=model_classifier2.predict(X_train.reshape(40000,32,400)/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_compressed=model_classifier2.predict(X_test.reshape(1000,32,400)/255)\n",
    "#np.save(\"img_compressed_train.npy\",X_train_compressed)\n",
    "#np.save(\"img_compressed_test.npy\",X_test_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_compressed=np.load(\"img_compressed_train.npy\")\n",
    "X_test_compressed=np.load(\"img_compressed_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m169/169\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_compressed=model_classifier2.predict(X_test_img.reshape(5400,32,400)/255)\n",
    "(X_test_img.reshape(5400,32,400)/255).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(255)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c=0\\n\\nfor i in range(200):\\n    a1=sum(a[i,:])\\n    indices = np.where(a1 == a1.max())\\n    #print(indices)\\n    b1=sum(y_autoencoder[i,:])\\n    indices1 = np.where(b1 == b1.max())\\n    print(indices1)\\n\\n    if indices==indices1:\\n       c=c+1\\n\\nprint(c)'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"c=0\n",
    "\n",
    "for i in range(200):\n",
    "    a1=sum(a[i,:])\n",
    "    indices = np.where(a1 == a1.max())\n",
    "    #print(indices)\n",
    "    b1=sum(y_autoencoder[i,:])\n",
    "    indices1 = np.where(b1 == b1.max())\n",
    "    print(indices1)\n",
    "\n",
    "    if indices==indices1:\n",
    "       c=c+1\n",
    "\n",
    "print(c)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_classifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def rossler_noise_generator(batch_size, num_steps, units, a=0.2, b=0.2, c=5.7):\n",
    "    # Initialize arrays to store Rssler system values\n",
    "    x = tf.TensorArray(dtype=tf.float32, size=num_steps)\n",
    "    y = tf.TensorArray(dtype=tf.float32, size=num_steps)\n",
    "    z = tf.TensorArray(dtype=tf.float32, size=num_steps)\n",
    "    \n",
    "    # Initial conditions as Gaussian noise with batch dimension\n",
    "    x_t = tf.random.normal((batch_size, units), mean=0.0, stddev=1.0)\n",
    "    y_t = tf.random.normal((batch_size, units), mean=0.0, stddev=1.0)\n",
    "    z_t = tf.random.normal((batch_size, units), mean=0.0, stddev=1.0)\n",
    "    \n",
    "    dt = 5.0/num_steps  # T/num_steps where T=10\n",
    "    \n",
    "    # Generate Rssler system trajectories\n",
    "    for t in tf.range(num_steps):\n",
    "        # Update equations\n",
    "        dx = -y_t - z_t\n",
    "        dy = x_t + a * y_t\n",
    "        dz = b + z_t * (x_t - c)\n",
    "        \n",
    "        x_t = x_t + dt * dx\n",
    "        y_t = y_t + dt * dy\n",
    "        z_t = z_t + dt * dz\n",
    "        \n",
    "        # Store current values\n",
    "        x = x.write(t, x_t)\n",
    "        y = y.write(t, y_t)\n",
    "        z = z.write(t, z_t)\n",
    "    \n",
    "    # Stack and transpose to get shape (batch_size, num_steps, units)\n",
    "    x = tf.transpose(x.stack(), [1, 0, 2])  # Shape: (batch_size, num_steps, units)\n",
    "    \n",
    "    return x  # Returns full time series with shape (batch_size, num_steps, units)\n",
    "\n",
    "@tf.function\n",
    "def real_cal(r, phi):\n",
    "    return r * tf.math.cos(phi)\n",
    "\n",
    "@tf.function\n",
    "def imag_cal(r, phi):\n",
    "    return r * tf.math.sin(phi)\n",
    "\n",
    "@tf.function\n",
    "def oscillator_loop_generator(X_r, X_i, omegas, num_steps):\n",
    "    # batch_size x timesteps X dim\n",
    "    r_arr = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True) # creates empty array to save r_t\n",
    "    phi_arr = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    r_t = tf.ones((tf.shape(X_r)[0], tf.shape(X_r)[-1])) # Initializing r_t\n",
    "    phis = tf.zeros((tf.shape(X_r)[0], tf.shape(X_r)[-1])) # Initislizing phi_t\n",
    "    dt = 1/128\n",
    "    input_scaler = 500\n",
    "    beta=1\n",
    "\n",
    "    for t in tf.range(num_steps):\n",
    "        input_r = input_scaler*X_r[:,t,:]*tf.math.cos(phis)\n",
    "        input_phi = input_scaler*X_i[:,t,:]*tf.math.sin(phis)\n",
    "        r_t = r_t + ((1 - beta*tf.square(r_t)) * r_t + input_r) * dt\n",
    "        phis = phis + (omegas - input_phi) * dt\n",
    "        r_arr = r_arr.write(r_arr.size(), r_t)  #1000,1,2\n",
    "        phi_arr = phi_arr.write(phi_arr.size(), phis)\n",
    "    r_arr = tf.transpose(r_arr.stack(), [1, 0, 2])  # Changing dimensions to 1,1000,2\n",
    "    phi_arr = tf.transpose(phi_arr.stack(), [1, 0, 2])\n",
    "    return r_arr, phi_arr\n",
    "\n",
    "class Hopf_gen(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, num_steps, min_omega=0.1,\n",
    "                 max_omega=64.1,train_omegas=True, **kwargs):\n",
    "        super(Hopf_gen, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.num_steps = num_steps\n",
    "        self.train_omegas=train_omegas\n",
    "        self.max_omega=max_omega\n",
    "        self.min_omega=min_omega\n",
    "        # self.omegas = tf.linspace(min_omega, max_omega, self.units) * (2*3.1415)\n",
    "        # self.omegas = tf.cast(tf.expand_dims(self.omegas, 0), 'float32')\n",
    "\n",
    "        omega_init=tf.random.uniform((1,self.units),-1,1)\n",
    "        self.omegas=tf.Variable(omega_init,trainable=self.train_omegas)\n",
    "\n",
    "    def call(self, X_r, X_i):\n",
    "        omega_intl = self.max_omega - self.min_omega\n",
    "        omega_inp = tf.sigmoid(0.5*self.omegas) * omega_intl + self.min_omega\n",
    "\n",
    "\n",
    "        r, phi = oscillator_loop_generator(X_r, X_i, omega_inp , self.num_steps)\n",
    "        z_real = real_cal(r, phi)\n",
    "        z_imag = imag_cal(r, phi)\n",
    "        return z_real, z_imag\n",
    "\n",
    "\n",
    "duration = 32\n",
    "\n",
    "class Model_generator(tf.keras.Model):\n",
    "    def __init__(self,  units5,units6,units7,units8,units9,units10 , **kwargs):\n",
    "        super(Model_generator, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "        # New layers beyond osc2\n",
    "        self.d3_r1 = tf.keras.layers.Dense(units5, activation='relu')\n",
    "        self.d3_i = tf.keras.layers.Dense(units5, activation='relu')\n",
    "        \n",
    "\n",
    "        self.osc3 = Hopf_gen(units6, num_steps=duration, min_omega=0.1, max_omega=64.1, train_omegas=True)\n",
    "    \n",
    "        self.d4_r = tf.keras.layers.Dense(units7, activation='relu')\n",
    "        self.d4_i = tf.keras.layers.Dense(units7, activation='relu')\n",
    "        \n",
    "        self.osc4 = Hopf_gen(units8, num_steps=duration, min_omega=0.1, max_omega=64.1, train_omegas=True)\n",
    "\n",
    "        self.d5=tf.keras.layers.Dense(units9,activation='tanh')\n",
    "        \n",
    "        self.out_dense=tf.keras.layers.Dense(units10,activation='linear')\n",
    "\n",
    "        #self.d4 = tf.keras.layers.Dense(units7, activation='tanh')\n",
    "        #self.out_dense = tf.keras.layers.Dense(units6, activation='linear')\n",
    "    \n",
    "    def call(self, X):\n",
    "\n",
    "        min_vals = tf.reduce_min(X, axis=-1, keepdims=True)\n",
    "        max_vals = tf.reduce_max(X, axis=-1, keepdims=True)\n",
    "\n",
    "        X = (X - min_vals) / (max_vals - min_vals + 1e-8)\n",
    "\n",
    "        out3_r1= tf.keras.layers.TimeDistributed(self.d3_r1)(X)\n",
    "        \n",
    "\n",
    "        out3_i = tf.keras.layers.TimeDistributed(self.d3_i)(X)\n",
    "        \n",
    "\n",
    "        z3_r, z3_i = self.osc3(out3_r1, out3_i)\n",
    "\n",
    "        #rossler_noise1 = rossler_noise_generator( tf.shape(X)[0], 32, tf.shape(z3_r)[-1])\n",
    "        rossler_noise1=tf.random.normal((tf.shape(z3_r)[0],32,z3_r.shape[2]),mean=0.0,stddev=1)\n",
    "        \"\"\"z3_r = tf.concat([z3_r, rossler_noise1], 2)\n",
    "        z3_i=tf.concat([z3_i,rossler_noise1],2)\"\"\"\n",
    "        z3_r = z3_r + rossler_noise1\n",
    "        z3_i = z3_i + rossler_noise1\n",
    "        out4_r = tf.keras.layers.TimeDistributed(self.d4_r)(z3_r)\n",
    "        \n",
    "        out4_i = tf.keras.layers.TimeDistributed(self.d4_i)(z3_i)\n",
    "        \n",
    "        out4_r_noise=tf.random.normal((tf.shape(out4_r)[0],32,out4_r.shape[2]),mean=0.0,stddev=1)\n",
    "        out4_i_noise=tf.random.normal((tf.shape(out4_i)[0],32,out4_i.shape[2]),mean=0.0,stddev=1)\n",
    "        out4_r = tf.concat([out4_r, out4_r_noise], 2)\n",
    "        out4_i=tf.concat([out4_i,out4_i_noise],2)\n",
    "        z4_r, z4_i = self.osc4(out4_r, out4_i)\n",
    "        \n",
    "        #z4_noise=tf.random.normal((tf.shape(z4_r)[0],32,z4_r.shape[2]),mean=0.0,stddev=0.5)\n",
    "        concat_inp2 = tf.concat([z4_r,z4_i], 2)\n",
    "        out4 = tf.keras.layers.TimeDistributed(self.d5)(concat_inp2)\n",
    "        out_final = tf.keras.layers.TimeDistributed(self.out_dense)(out4)\n",
    "\n",
    "        return out_final\n",
    "\n",
    "model_generator = Model_generator(20, 20,10,20,20,14)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_classifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def rossler_noise_generator(batch_size, num_steps, units, a=0.2, b=0.2, c=5.7):\n",
    "    # Initialize arrays to store Rssler system values\n",
    "    x = tf.TensorArray(dtype=tf.float32, size=num_steps)\n",
    "    y = tf.TensorArray(dtype=tf.float32, size=num_steps)\n",
    "    z = tf.TensorArray(dtype=tf.float32, size=num_steps)\n",
    "    \n",
    "    # Initial conditions as Gaussian noise with batch dimension\n",
    "    x_t = tf.random.normal((batch_size, units), mean=0.0, stddev=1.0)\n",
    "    y_t = tf.random.normal((batch_size, units), mean=0.0, stddev=1.0)\n",
    "    z_t = tf.random.normal((batch_size, units), mean=0.0, stddev=1.0)\n",
    "    \n",
    "    dt = 5.0/num_steps  # T/num_steps where T=10\n",
    "    \n",
    "    # Generate Rssler system trajectories\n",
    "    for t in tf.range(num_steps):\n",
    "        # Update equations\n",
    "        dx = -y_t - z_t\n",
    "        dy = x_t + a * y_t\n",
    "        dz = b + z_t * (x_t - c)\n",
    "        \n",
    "        x_t = x_t + dt * dx\n",
    "        y_t = y_t + dt * dy\n",
    "        z_t = z_t + dt * dz\n",
    "        \n",
    "        # Store current values\n",
    "        x = x.write(t, x_t)\n",
    "        y = y.write(t, y_t)\n",
    "        z = z.write(t, z_t)\n",
    "    \n",
    "    # Stack and transpose to get shape (batch_size, num_steps, units)\n",
    "    x = tf.transpose(x.stack(), [1, 0, 2])  # Shape: (batch_size, num_steps, units)\n",
    "    \n",
    "    return x  # Returns full time series with shape (batch_size, num_steps, units)\n",
    "\n",
    "@tf.function\n",
    "def real_cal(r, phi):\n",
    "    return r * tf.math.cos(phi)\n",
    "\n",
    "@tf.function\n",
    "def imag_cal(r, phi):\n",
    "    return r * tf.math.sin(phi)\n",
    "\n",
    "@tf.function\n",
    "def oscillator_loop_generator(X_r, X_i, omegas, num_steps):\n",
    "    # batch_size x timesteps X dim\n",
    "    r_arr = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True) # creates empty array to save r_t\n",
    "    phi_arr = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    r_t = tf.ones((tf.shape(X_r)[0], tf.shape(X_r)[-1])) # Initializing r_t\n",
    "    #phis = tf.random.uniform(0,1,(tf.shape(X_r)[0], tf.shape(X_r)[-1])) # Initislizing phi_t\n",
    "    phis = tf.random.uniform(shape=[tf.shape(X_r)[0], tf.shape(X_r)[-1]], minval=0, maxval=0.785)\n",
    "    r_t=tf.random.uniform(shape=[tf.shape(X_r)[0], tf.shape(X_r)[-1]], minval=0, maxval=0.5)\n",
    "    dt = 1/128\n",
    "    input_scaler = 100\n",
    "    beta=1\n",
    "\n",
    "    for t in tf.range(num_steps):\n",
    "        input_r = input_scaler*X_r[:,t,:]*tf.math.cos(phis)\n",
    "        input_phi = input_scaler*X_i[:,t,:]*tf.math.sin(phis)\n",
    "        r_t = r_t + ((1 - beta*tf.square(r_t)) * r_t + input_r) * dt\n",
    "        phis = phis + (omegas - input_phi) * dt\n",
    "        r_arr = r_arr.write(r_arr.size(), r_t)  #1000,1,2\n",
    "        phi_arr = phi_arr.write(phi_arr.size(), phis)\n",
    "    r_arr = tf.transpose(r_arr.stack(), [1, 0, 2])  # Changing dimensions to 1,1000,2\n",
    "    phi_arr = tf.transpose(phi_arr.stack(), [1, 0, 2])\n",
    "    return r_arr, phi_arr\n",
    "\n",
    "class Hopf_gen(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, num_steps, min_omega=0.1,\n",
    "                 max_omega=64.1,train_omegas=True, **kwargs):\n",
    "        super(Hopf_gen, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.num_steps = num_steps\n",
    "        self.train_omegas=train_omegas\n",
    "        self.max_omega=max_omega\n",
    "        self.min_omega=min_omega\n",
    "        # self.omegas = tf.linspace(min_omega, max_omega, self.units) * (2*3.1415)\n",
    "        # self.omegas = tf.cast(tf.expand_dims(self.omegas, 0), 'float32')\n",
    "\n",
    "        omega_init=tf.random.uniform((1,self.units),-1,1)\n",
    "        self.omegas=tf.Variable(omega_init,trainable=self.train_omegas)\n",
    "\n",
    "    def call(self, X_r, X_i):\n",
    "        omega_intl = self.max_omega - self.min_omega\n",
    "        omega_inp = tf.sigmoid(0.5*self.omegas) * omega_intl + self.min_omega\n",
    "\n",
    "\n",
    "        r, phi = oscillator_loop_generator(X_r, X_i, omega_inp , self.num_steps)\n",
    "        z_real = real_cal(r, phi)\n",
    "        z_imag = imag_cal(r, phi)\n",
    "        return z_real, z_imag\n",
    "\n",
    "\n",
    "duration = 32\n",
    "\n",
    "class Model_generator(tf.keras.Model):\n",
    "    def __init__(self,  units5,units6,units7,units8,units9,units10 , **kwargs):\n",
    "        super(Model_generator, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "        # New layers beyond osc2\n",
    "        self.d3_r1 = tf.keras.layers.Dense(units5, activation='relu')\n",
    "        self.d3_i = tf.keras.layers.Dense(units5, activation='relu')\n",
    "        \n",
    "\n",
    "        self.osc3 = Hopf_gen(units6, num_steps=duration, min_omega=0.1, max_omega=64.1, train_omegas=True)\n",
    "        self.bn1=tf.keras.layers.BatchNormalization(center=False, scale=False)\n",
    "        self.d4_r = tf.keras.layers.Dense(units7, activation='relu')\n",
    "        self.bn2=tf.keras.layers.BatchNormalization(center=False, scale=False)\n",
    "        self.d4_i = tf.keras.layers.Dense(units7, activation='relu')\n",
    "        self.bn3=tf.keras.layers.BatchNormalization(center=False, scale=False)\n",
    "        self.osc4 = Hopf_gen(units8, num_steps=duration, min_omega=0.1, max_omega=64.1, train_omegas=True)\n",
    "        self.bn4=tf.keras.layers.BatchNormalization(center=False, scale=False)\n",
    "        self.d5=tf.keras.layers.Dense(units9,activation='tanh')\n",
    "        self.bn5=tf.keras.layers.BatchNormalization(center=False, scale=False)\n",
    "        self.out_dense=tf.keras.layers.Dense(units10,activation='linear')\n",
    "        self.bn6=tf.keras.layers.BatchNormalization(center=False, scale=False)\n",
    "        self.bn7=tf.keras.layers.BatchNormalization(center=False, scale=False)\n",
    "        #self.d4 = tf.keras.layers.Dense(units7, activation='tanh')\n",
    "        #self.out_dense = tf.keras.layers.Dense(units6, activation='linear')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        X1=inputs[0]\n",
    "        X2=inputs[1]\n",
    "\n",
    "        min_vals = tf.reduce_min(X1, axis=-1, keepdims=True)\n",
    "        max_vals = tf.reduce_max(X1, axis=-1, keepdims=True)\n",
    "\n",
    "        X1 = (X1 - min_vals) / (max_vals - min_vals + 1e-8)\n",
    "\n",
    "        min_vals = tf.reduce_min(X2, axis=-1, keepdims=True)\n",
    "        max_vals = tf.reduce_max(X2, axis=-1, keepdims=True)\n",
    "\n",
    "        X2 = (X2 - min_vals) / (max_vals - min_vals + 1e-8)\n",
    "\n",
    "        #X=tf.random.normal((tf.shape(X1)[0],32,X1.shape[2]),mean=0.0,stddev=1)\n",
    "        Z1=tf.random.normal((tf.shape(X1)[0],32,X1.shape[2]),mean=0.0,stddev=1)\n",
    "        Z2=tf.random.normal((tf.shape(X1)[0],32,X1.shape[2]),mean=0.2,stddev=1)\n",
    "        Z3=tf.random.normal((tf.shape(X1)[0],32,X1.shape[2]),mean=-0.2,stddev=1)\n",
    "        Z=Z1+Z2+Z3\n",
    "        Z=self.bn1(Z)\n",
    "        X=Z*X1+X2        \n",
    "        #X=X*X1+X2\n",
    "\n",
    "        out3_r1= tf.keras.layers.TimeDistributed(self.d3_r1)(X)\n",
    "        #out3_r=self.bn1(out3_r1)\n",
    "        #out3_r1=out3_r*X1+X2\n",
    "        out3_i = tf.keras.layers.TimeDistributed(self.d3_i)(X)\n",
    "        #out3_i=self.bn2(out3_i)\n",
    "        #out3_i=out3_i*X1+X2\n",
    "        \n",
    "\n",
    "        z3_r, z3_i = self.osc3(out3_r1, out3_i)\n",
    "        #rossler_noise1=tf.random.normal((tf.shape(z3_r)[0],32,z3_r.shape[2]),mean=0.0,stddev=1)\n",
    "        \n",
    "        #z3_r = z3_r + rossler_noise1\n",
    "        #z3_i = z3_i + rossler_noise1\n",
    "        #z3_r=self.bn3(z3_r)\n",
    "        #z3_r=z3_r*X1+X2\n",
    "        #z3_i=self.bn4(z3_i)\n",
    "        #z3_i=z3_i*X1+X2\n",
    "        out4_r = tf.keras.layers.TimeDistributed(self.d4_r)(z3_r)\n",
    "        #out4_r=self.bn5(out4_r)\n",
    "        #out4_r=out4_r*X1+X2\n",
    "        \n",
    "        out4_i = tf.keras.layers.TimeDistributed(self.d4_i)(z3_i)\n",
    "        out4_r_noise=tf.random.normal((tf.shape(out4_r)[0],32,out4_r.shape[2]),mean=0.0,stddev=1)\n",
    "        out4_i_noise=tf.random.normal((tf.shape(out4_i)[0],32,out4_i.shape[2]),mean=0.0,stddev=1)\n",
    "        #out4_r=out4_r+out4_r_noise\n",
    "        #out4_i=out4_i+out4_i_noise\n",
    "        #out4_i=self.bn6(out4_i)\n",
    "        #out4_i=out4_i*X1+X2\n",
    "        \n",
    "        #out4_r_noise=tf.random.normal((tf.shape(out4_r)[0],32,out4_r.shape[2]),mean=0.0,stddev=1)\n",
    "        #out4_i_noise=tf.random.normal((tf.shape(out4_i)[0],32,out4_i.shape[2]),mean=0.0,stddev=1)\n",
    "        #out4_r = tf.concat([out4_r, out4_r_noise], 2)\n",
    "        #out4_i=tf.concat([out4_i,out4_i_noise],2)\n",
    "        z4_r, z4_i = self.osc4(out4_r, out4_i)\n",
    "        #z4_r=self.bn7(z4_r)\n",
    "        #z4_r=z4_r*X1+X2\n",
    "        #z4_i=self.bn7(z4_i)\n",
    "        #z4_i=z4_i*X1+X2\n",
    "        \n",
    "        #z4_noise=tf.random.normal((tf.shape(z4_r)[0],32,z4_r.shape[2]),mean=0.0,stddev=0.5)\n",
    "        concat_inp2 = tf.concat([z4_r,z4_i], 2)\n",
    "        out4 = tf.keras.layers.TimeDistributed(self.d5)(concat_inp2)\n",
    "        out_final = tf.keras.layers.TimeDistributed(self.out_dense)(out4)\n",
    "\n",
    "        return out_final\n",
    "\n",
    "#model_generator = Model_generator(20, 20,10,20,20,14)\n",
    "model_generator = Model_generator(40, 40,40,40,30,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dense name=dense_28, built=False>\n",
      "Weights of layer dense_28:\n",
      "<Dense name=dense_29, built=False>\n",
      "Weights of layer dense_29:\n",
      "<Hopf_gen name=hopf_gen_2, built=False>\n",
      "Weights of layer hopf_gen_2:\n",
      "<BatchNormalization name=batch_normalization, built=False>\n",
      "Weights of layer batch_normalization:\n",
      "<Dense name=dense_30, built=False>\n",
      "Weights of layer dense_30:\n",
      "<BatchNormalization name=batch_normalization_1, built=False>\n",
      "Weights of layer batch_normalization_1:\n",
      "<Dense name=dense_31, built=False>\n",
      "Weights of layer dense_31:\n",
      "<BatchNormalization name=batch_normalization_2, built=False>\n",
      "Weights of layer batch_normalization_2:\n",
      "<Hopf_gen name=hopf_gen_3, built=False>\n",
      "Weights of layer hopf_gen_3:\n",
      "<BatchNormalization name=batch_normalization_3, built=False>\n",
      "Weights of layer batch_normalization_3:\n",
      "<Dense name=dense_32, built=False>\n",
      "Weights of layer dense_32:\n",
      "<BatchNormalization name=batch_normalization_4, built=False>\n",
      "Weights of layer batch_normalization_4:\n",
      "<Dense name=dense_33, built=False>\n",
      "Weights of layer dense_33:\n",
      "<BatchNormalization name=batch_normalization_5, built=False>\n",
      "Weights of layer batch_normalization_5:\n",
      "<BatchNormalization name=batch_normalization_6, built=False>\n",
      "Weights of layer batch_normalization_6:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Access and print the weights of individual layers\n",
    "for layer in model_generator.layers:\n",
    "    print(layer)\n",
    "    layer_weights = layer.get_weights()\n",
    "    print(f\"Weights of layer {layer.name}:\")\n",
    "    for weight in layer_weights:\n",
    "        print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Access the layer by name\\nlayer_name = \\'dense_16\\'  # Replace with the actual layer name\\nlayer = model_generator.get_layer(name=layer_name)\\n\\n# Get the weights of the layer\\nweights = layer.get_weights()\\n\\n# Print the weights\\nprint(f\"Weights of layer {layer_name}:\")\\nfor weight in weights:\\n    print(weight.shape)\\n    print(weight[:20].mean())\\n    print(weight[20:].mean())'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Access the layer by name\n",
    "layer_name = 'dense_16'  # Replace with the actual layer name\n",
    "layer = model_generator.get_layer(name=layer_name)\n",
    "\n",
    "# Get the weights of the layer\n",
    "weights = layer.get_weights()\n",
    "\n",
    "# Print the weights\n",
    "print(f\"Weights of layer {layer_name}:\")\n",
    "for weight in weights:\n",
    "    print(weight.shape)\n",
    "    print(weight[:20].mean())\n",
    "    print(weight[20:].mean())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 32, 25)\n"
     ]
    }
   ],
   "source": [
    "X_autoencoder_compressed=model_classifier2(X_autoencoder/255)\n",
    "print(X_autoencoder_compressed[0].shape)\n",
    "X_autoencoder_compressed=np.array(X_autoencoder_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train_compressed1 = []\\nfor i in range(200):\\n    # Create concatenated input from both real and imaginary parts\\n    current_sample = X_autoencoder_compressed[0][i:i+1]\\n    X_train_compressed1 += np.repeat(current_sample, repeats=200, axis=0).tolist()\\nX_train_compressed1 = np.array(X_train_compressed1)'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_train_compressed1 = []\n",
    "for i in range(200):\n",
    "    # Create concatenated input from both real and imaginary parts\n",
    "    current_sample = X_autoencoder_compressed[0][i:i+1]\n",
    "    X_train_compressed1 += np.repeat(current_sample, repeats=200, axis=0).tolist()\n",
    "X_train_compressed1 = np.array(X_train_compressed1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_compressed1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train_compressed2 = []\\nfor i in range(200):\\n    # Create concatenated input from both real and imaginary parts\\n    current_sample = X_autoencoder_compressed[1][i:i+1]\\n    X_train_compressed2 += np.repeat(current_sample, repeats=200, axis=0).tolist()\\nX_train_compressed2 = np.array(X_train_compressed2)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_train_compressed2 = []\n",
    "for i in range(200):\n",
    "    # Create concatenated input from both real and imaginary parts\n",
    "    current_sample = X_autoencoder_compressed[1][i:i+1]\n",
    "    X_train_compressed2 += np.repeat(current_sample, repeats=200, axis=0).tolist()\n",
    "X_train_compressed2 = np.array(X_train_compressed2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_compressed=[X_train_compressed1,X_train_compressed2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=model_generator([X_autoencoder_compressed[0],X_autoencoder_compressed[1]])\n",
    "y=model_generator([X_autoencoder_compressed[0],X_autoencoder_compressed[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nfrom sklearn.cluster import KMeans\\n\\n# Assuming your data is a 200x25 NumPy array\\n\\n# Initialize KMeans with the desired number of clusters (e.g., 5 clusters)\\nX_pca=X_autoencoder_compressed[:,0,:]\\nkmeans = KMeans(n_clusters=10, random_state=42)\\n\\n# Fit the model to the data\\nkmeans.fit(X_pca)\\n\\n# Get the cluster labels\\nlabels = kmeans.labels_\\n\\n# Print the labels\\nprint(labels)'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming your data is a 200x25 NumPy array\n",
    "\n",
    "# Initialize KMeans with the desired number of clusters (e.g., 5 clusters)\n",
    "X_pca=X_autoencoder_compressed[:,0,:]\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "\n",
    "# Fit the model to the data\n",
    "kmeans.fit(X_pca)\n",
    "\n",
    "# Get the cluster labels\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Print the labels\n",
    "print(labels)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_autoencoder_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "array([-0.74663645, -0.8219425 , -0.7665651 , -0.65561736, -0.4730778 ,\n",
       "       -0.4139045 , -0.4032091 , -0.4349712 , -0.512594  , -0.48659727,\n",
       "       -0.45720544, -0.41234988, -0.4574712 , -0.522609  , -0.40798107,\n",
       "       -0.25337017, -0.15459882, -0.23925388, -0.5559104 , -0.9471142 ,\n",
       "       -1.2423453 , -1.5528711 , -1.7409469 , -1.7790248 , -1.44449   ,\n",
       "       -0.9179803 , -0.13472137,  0.4740832 ,  0.73634833,  1.02109   ,\n",
       "        0.927867  ,  0.10022953], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[21,:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.plot(x[20,:,6])\\nplt.plot(x[40,:,6])\\nplt.plot(x[60,:,6])\\nplt.plot(x[80,:,6])\\nplt.plot(x[100,:,6])\\nplt.plot(x[120,:,6])\\nplt.plot(x[140,:,6])\\nplt.plot(x[160,:,6])'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABmJklEQVR4nO3dd3hUZfrG8e+kk5BCSCABQg0QagjVCAIKSlEEOzbEgit2cS24+9N11WXVtfeOFREVRVGUIgjSS+gEQkso6ZBK6pzfH4cEUFogM2dmcn+ua645JJM5D+PI3HnP876vzTAMAxERERE34WV1ASIiIiI1ofAiIiIibkXhRURERNyKwouIiIi4FYUXERERcSsKLyIiIuJWFF5ERETErSi8iIiIiFvxsbqA2ma329m3bx/BwcHYbDaryxEREZHTYBgGBQUFNGnSBC+vk4+teFx42bdvHzExMVaXISIiImcgLS2NZs2anfQxHhdegoODAfMvHxISYnE1IiIicjry8/OJiYmp/hw/GY8LL1WXikJCQhReRERE3MzptHyoYVdERETcisKLiIiIuBWFFxEREXErCi8iIiLiVhReRERExK0ovIiIiIhbUXgRERERt6LwIiIiIm5F4UVERETcisKLiIiIuBWFFxEREXErCi8iIiLiVhwaXn7//XdGjBhBkyZNsNlsfPfdd6f8mfnz59O9e3f8/f2JjY1l8uTJjixRRETEPVVWwPL3YM9KqytxOoeGl6KiIuLj43njjTdO6/E7d+7k4osv5vzzzycpKYn777+f2267jV9++cWRZYqIiLifFe/DT3+HDy6ERS+BYVhdkdPYDMM5f1ubzcb06dMZNWrUCR/zyCOPMHPmTDZs2FD9tdGjR3Pw4EFmzZp1WufJz88nNDSUvLw8QkJCzrZsERER12O3w+s9IHfHka+1Hw6j3oJ6YZaVdTZq8vntUj0vS5YsYfDgwcd8bciQISxZsuSEP1NaWkp+fv4xNxEREY+2fa4ZXPxDYeh/wdsPkn+CdwfA/rVWV+dwLhVe0tPTady48TFfa9y4Mfn5+Rw6dOi4PzNp0iRCQ0OrbzExMc4oVURExDrL3jHvE26Ac8bDLb9AaHM4sAvevxBWf2JpeY7mUuHlTEycOJG8vLzqW1pamtUliYiIOE7OdkiZDdig923m15p2h78tgLYXQWUpzLgHvrsLyo//i7+7c6nwEhUVRUZGxjFfy8jIICQkhHr16h33Z/z9/QkJCTnmJiIi4rGWv2fet70Iwlsf+XpgOFw7FS74J9i8IOkzcxQmZ7s1dTqQS4WXxMRE5s6de8zXZs+eTWJiokUViYiIuJDSQkj63Dzuc/tfv+/lBf0fghunQ2AEZKyHdwfC5h+dWqajOTS8FBYWkpSURFJSEmBOhU5KSiI1NRUwL/mMGTOm+vF33HEHO3bs4OGHH2bLli28+eabfPXVVzzwwAOOLFNERMQ9rJ0CpfnQMBZaX3Dix7UeCHcshJg+5uOnXg+//p+5NowHcGh4WblyJQkJCSQkJAAwYcIEEhISePzxxwHYv39/dZABaNWqFTNnzmT27NnEx8fzwgsv8P777zNkyBBHlikiIuL6DOPIJaPet5ujLCcT0gTGzoRz7jL/vPhV+ORSKEh3bJ1O4LR1XpxF67yIiIhH2v4bfDoK/OrDhM0QUIPPuI3fwfd3Q1kBBDWCqz6Clv0cVekZcdt1XkREROQElr9r3ne7rmbBBaDTKLh9PjTqCEWZ8PEI+OOV2q7QaRReREREXN2BXZD8s3nc+ziNuqcjIhZumwNdR4Nhh9mPQ+qyWivRmRReREREXN2K9wED2lwAEW3P/Hn8guCytyH2QvPP+9bUSnnOpvAiIiLiysqKYfWn5nHvv53989ls0LiTeZzrnmvAKLyIiIi4svVfQclBaNAS2l5YO8/ZsI15n5NSO8/nZAovIiIirsowYNnhRt1e48DLu3aet2Gsee+mq+8qvIiIiLiq3X9A5kbwDTQ3Yawt4YdHXvLSoKK09p7XSRReREREXFXV7tFdr4F6YbX3vPUbgV+wOevowK7ae14nUXgRERFxRXl7YMtM8/hMp0efiM0GDQ9v6uiGfS8KLyIiIq5o5YdgVELL86Bxx9p/fjfue1F4ERERcTXlJbBqsnncpxamRx9PuPvOOFJ4ERERcTUbv4XiHAiNgXbDHHOOqpGX3B2OeX4HUngRERFxJYZxpFG3163g7eOY87jxWi8KLyIiIq5kzwrYnwTe/pAwxnHnCT/csFuwH0oLHXceB1B4ERERcSVVoy5droKgho47T2A41As3j93s0pHCi4iIiKsoSIdN35nHfWp5evTxVPe9uNeMI4UXERERV7HyI7BXQMw5EB3v+PO5ad+LwouIiIgrqCiDVR+Zx84YdYGjwosuG4mIiEhNbfoeCjMgOBo6XOqcc7rpWi8KLyIiIq5g+eFG3Z63gLevc86pnhcRERE5I3tXm1Okvf2gx1jnnbdqunRxDhw64LzzniWFFxEREastf9e873SZueOzs/jXNy9TgVv1vSi8iIiIWKkwCzZ8Yx73dtA+Rifjhn0vCi8iIiJWWj0ZKsugaQ9o1sP556+aceRGfS8KLyIiIlapKIMVH5jHVoy6gFuu9aLwIiIiYpX1X5l7CwVHm/0uVqiacZSjkRcRERE5Gbsd/njVPD7nTvDxs6aO6p6X7eaO1m5A4UVERMQK236B7GTwD3Xu9Og/C28F2KCsAIqyrKujBhReRERErLDoZfO+1y0QEGJdHT7+EBZjHrtJ34vCi4iIiLOlLoW0peaidH3usLoat+t7UXgRERFxtqpel/jREBxlbS3gdmu9KLyIiIg4U1YyJM8EbHDuvVZXY3KzPY4UXkRERJxp8eFRl7iLIaKttbVUaXjUjCM3oPAiIiLiLPn7Ye1U87jv/ZaWcozqVXZ3mFO4XZzCi4iIiLMsfRPs5dD8XIjpZXU1R4Q2By8fqCiB/L1WV3NKCi8iIiLOUJIHKz8yj/vdb2kpf+HtAw1amcdu0Pei8CIiIuIMKz8yF4KL7ACxF1pdzV+50R5HCi8iIiKOVlEKS98yj/veC14u+PFbvdbLDmvrOA0u+OqJiIh4mHVToTAdQppC5yutrub4wlub9xp5ERERqeNcZQPGU3GjtV4UXkRERBwp+SfI2QYBodDjJqurObGqnpcDu6CywtJSTkXhRURExFEMA/542TzudRv4B1tazkkFNwGfemCvgIO7ra7mpBReREREHCV1KexZAd7+0PtvVldzcl5eR/W9uPalI4UXERERR6kadel2LQQ3trSU01K90q7Ci4iISN2TuRm2zsKlNmA8FTdZ60XhRURExBEWv2bedxhxJBS4uuq1XjTyIiIiUrfk7YV1X5nHfe+ztpaaCHeP3aUVXkRERGpb1QaMLfpBs55WV3P6qkZe8tKgvMTaWk5C4UVERKQ2HToIqyabx662AeOpBEWAfwhgwIGdVldzQk4JL2+88QYtW7YkICCAPn36sHz58hM+dvLkydhstmNuAQEBzihTRETk7K38EMoKoVFHiB1sdTU1Y7Md1bTrupeOHB5epk6dyoQJE3jiiSdYvXo18fHxDBkyhMzMzBP+TEhICPv376++7d7t2ovliIiIAOalluoNGO8zw4C7CXf9GUcODy8vvvgi48aN4+abb6Zjx468/fbbBAYG8uGHH57wZ2w2G1FRUdW3xo3dYG68iIjIui+hKBNCmkHnK6yu5sy4wR5HDg0vZWVlrFq1isGDjwybeXl5MXjwYJYsWXLCnyssLKRFixbExMQwcuRINm7ceMLHlpaWkp+ff8xNRETE6eyVR6ZHJ94F3r7W1nOm6vplo+zsbCorK/8yctK4cWPS09OP+zPt27fnww8/5Pvvv+ezzz7Dbrdz7rnnsmfPnuM+ftKkSYSGhlbfYmJiav3vISIickpbZpqXWgLCoPsYq6s5c3U9vJyJxMRExowZQ7du3RgwYADffvstkZGRvPPOO8d9/MSJE8nLy6u+paWlObliERGp847egLH3OPCvb2k5Z6Wq56UwHUoLrK3lBHwc+eQRERF4e3uTkZFxzNczMjKIioo6refw9fUlISGBlJTjNw75+/vj7+9/1rWKiIicsdQlsHeVe2zAeCr1wiAwAoqzIXcHRMdbXdFfOHTkxc/Pjx49ejB37tzqr9ntdubOnUtiYuJpPUdlZSXr168nOjraUWWKiIicnW2zzftOl0H9SGtrqQ0uvseRwy8bTZgwgffee4+PP/6YzZs3M378eIqKirj55psBGDNmDBMnTqx+/L///W9+/fVXduzYwerVq7nhhhvYvXs3t912m6NLFREROTP7k8z7mN6WllFrqvc42mFtHSfg0MtGANdccw1ZWVk8/vjjpKen061bN2bNmlXdxJuamoqX15EMdeDAAcaNG0d6ejoNGjSgR48eLF68mI4dOzq6VBERkZozDNiXZB436WZlJbUnvLV576IjLzbDMAyri6hN+fn5hIaGkpeXR0hIiNXliIiIpzuYCi93AS8fmLgXfD1gVfiN38G0m6BZL7htjlNOWZPPb5ebbSQiIuJWqkZdGnXwjOAC6nkRERHxaFX9LtHdrKyidlVdNjp0AIpzra3lOBReREREzoan9bsA+AVBcBPz2AUXq1N4EREROVOGcdTIS4KlpdS6qktHLrjHkcKLiIjImcrbA8U5ZrNu405WV1O7XLjvReFFRETkTFWNukR6ULNuleq1XjTyIiIi4jmq+11cbwn9sxaukRcRERHP44kzjapUjbzk7jB7e1yIwouIiMiZOGZlXQ9r1gVo0BJsXlBWCIUZp3y4Mym8iIiInIn8vebOyzZvz2vWBfDxg7Dm5rGL9b0ovIiIiJyJY1bWrWdpKQ7jon0vCi8iIiJnYv9a894T+12qVPe9aORFRETE/VU363rgTKMq1Wu9KLyIiIi4t2OadbtZWYljKbyIiIh4iIL9UJRpzsZp3NnqahynqucldwfY7dbWchSFFxERkZqqGnWJjAO/QEtLcaiw5uDlC5WlkL/H6mqqKbyIiIjUlCcvTnc0L28Ib2Ueu9CMI4UXERGRmqoL/S5VXHCPI4UXERGRmqorIy8A4a3Ne4UXERERN5W/31wu3+YFUV2srsbxXHCtF4UXERGRmqgadYlo79nNulUaut4quwovIiIiNVGX+l3gyMjLgd1QWW5tLYcpvIiIiNREXep3AQiOBt9AMCrNAOMCFF5ERERqoq6NvNhsRy1W5xp9LwovIiIip6sgHQrT606zbpWGVTOOXKPvReFFRETkdFWNukS0A78gS0txKhdb60XhRURE5HTVtX6XKuGuNeNI4UVEROR01bV+lyrVa73ssLaOwxReRERETlddHXmpWuslLw3KD1lbCwovIiIip6cgAwr2A7a61awLENgQAkLN49yd1taCwouIiMjpqV5Ztx3417e0FKc7erq0C/S9KLyIiIicjrra71LFhfY4UngRERE5HXW136WKC+1xpPAiIiJyOjTyYt7nWD/jSOFFRETkVAozoWAfZrNuV6ursUa466yyq/AiIiJyKtUr67ate826VaouGxVlQkm+paX4WHp2ERERd+Bh/S7ztmTwzaq9NAkLoFVEfVpFBNE6MohGwf7YbLbj/1BAKARFQlGW2bTbJMG5RR9F4UVERORUPKjfxTAM/u+7jew9+NfF5gL9vGkVEfSXW+uI+oQG+pp9L0VZ5h5HCi8iIiIuzINGXrZnFbH34CH8fLy4vk9zdmUXsTO7iLQDhyguq2Tjvnw27vvrZaHwID+e963PIGDl6hX07HKl84s/TOFFRETkZAqzIH8vYINo92/W/X1rFgC9W4bzxIhO1V8vq7CTdqCYnVlmmNmRXcTO7EJ2ZheRkV9KblEZK70bMsgXctO2WFU+oPAiIiJyclWjLg1jwT/Y0lJqw+/bzPAyoF3kMV/38/GiTWR92kT+tSG5sLSCXdlFlKzNguVf0i0w2ym1nojCi4iIyMl4UL9LSXklS3fkAND/T+HlZOr7+9C5aSj49ILl0Mi7yFElnhaFFxERkZOp7neJt7SM2rBiVy4l5XaiQgJo1/gMpnxHtIeHd0JgeO0XVwNa50VERORkqkZePKBZt6rfpX+7iBNPiT4Zbx/LgwsovIiIiJxYUTbk7zGPPaBZd0F1eDn9S0auSOFFRETkRKpGXcLbmIu0ubH9eYfYmlGIlw36xUZYXc5ZUXgRERE5kf1rzHsPaNatumQUHxNGWKCfxdWcHYUXERGRE/GofhdzenP/tu59yQgUXkRERE5s/1rz3s1HXioq7SxKMcPLgPYKL6fljTfeoGXLlgQEBNCnTx+WL19+0sdPmzaNuLg4AgIC6NKlCz/99JMzyhQRETmiKAfy0sxjN58mvXZPHnmHygmt50t8szCryzlrDg8vU6dOZcKECTzxxBOsXr2a+Ph4hgwZQmZm5nEfv3jxYq699lpuvfVW1qxZw6hRoxg1ahQbNmxwdKkiIiJHVPW7hLd2+2bdqn6XfrEReHudwRRpF+Pw8PLiiy8ybtw4br75Zjp27Mjbb79NYGAgH3744XEf/8orrzB06FAeeughOnTowFNPPUX37t15/fXXHV2qiIjIER7U71I1RfrPWwK4K4eGl7KyMlatWsXgwYOPnNDLi8GDB7NkyZLj/sySJUuOeTzAkCFDTvj40tJS8vPzj7mJiIicNQ/pdzlYXMa6PQcBOK+de0+RruLQ8JKdnU1lZSWNGzc+5uuNGzcmPT39uD+Tnp5eo8dPmjSJ0NDQ6ltMTEztFC8iInVb9bYA3ays4qwtSsnGbkC7xvWJDq1ndTm1wu1nG02cOJG8vLzqW1pamtUliYiIuyvOhYOp5rGbN+suSPasS0bg4I0ZIyIi8Pb2JiMj45ivZ2RkEBUVddyfiYqKqtHj/f398ff3r52CRURE4MioS4NWUC/MykrOimEY/L7NM7YEOJpDR178/Pzo0aMHc+fOrf6a3W5n7ty5JCYmHvdnEhMTj3k8wOzZs0/4eBERkVpX1azr5v0uyRkFZOSXEuDrRa+W1m+oWFscOvICMGHCBG666SZ69uxJ7969efnllykqKuLmm28GYMyYMTRt2pRJkyYBcN999zFgwABeeOEFLr74Yr788ktWrlzJu+++6+hSRURETB7S71I1Rfqc1g0J8PW2uJra4/Dwcs0115CVlcXjjz9Oeno63bp1Y9asWdVNuampqXh5HRkAOvfcc/niiy/45z//yWOPPUbbtm357rvv6Ny5s6NLFRERMXnIyIsnbQlwNJthGIbVRdSm/Px8QkNDycvLIyQkxOpyRCxzsLiM7VmFbM8q4mBxGcM6RxMTHmh1WSKurzgXnmtlHj+yC+o1sLScM1VcVkG3J2dTVmln7oMDaBNZ3+qSTqomn98OH3kREcepqLSTduAQO7IK2Z5VyI6sour7nKKyYx777KxkLk9oyl3nx9IyIsiiikXcQNX6Lg1aum1wAVi2I5eySjtNw+rR2sP+n1d4EXETO7OLWLX7wOFwYo6o7M4porzyxIOn0aEBtImsT3mlnWU7c5m2ag/frN7DqG5NueuCWJf/TUzEEh7S71K1qm7/dpHYbO6/JcDRFF5EXJxhGLy3cAf//XkL9uPklABfL1pF1KdNZBCtI837NpH1aRURRJD/kf/FV6ce4LW52/gtOYtv1+xletJeLunahHsuiKVd42An/o1EXJzH9Lt43vouVRReRFxYYWkFj3y9jpnr9wPQvXkYnZqE0vpwQGkdGUST0Hp4ncZGa92bN+Cjm3uzbs9BXpuXwuxNGfywdh8/rN3H8C5R3H1+Wzo2UZ+YiCeMvKTlFrMjuwhvLxvnxja0upxap/Ai4qK2ZxVyx6er2JZZiK+3jcdHdOKGPs3Pevi3a7Mw3hvTk4378nh9Xgo/b0jnp/Xm7cKOjbn3grZ0aebeO+iKnLFDB+DALvPYjVfWrbpk1L15GCEBvhZXU/sUXkRc0C8b03nwq7UUllbQKNift27oTo8WtbvAVKcmobx1Qw+2pOfz+rwUZq7fz+xNGczelMEFcY2454JYEpq7b7OiyBmpatYNawGB7ruomydfMgKFFxGXUmk3eGn2Vl7/LQWA3i3Def36BBoFBzjsnHFRIbx+XXfuzyzg9XkpzFi7j3lbMpm3JZPz2kZwzwVt6dWygcc1/Ikclwf0u5RX2lm8PQfwrC0BjqbwIuIiDhSVcd/UpOrfmG7u25LHhnfA19s5+6fGNgrm5dEJ3De4HW/8lsL0NXtZuC2bhduy6dw0hLHntmJEfDT+Pp6zSqfIX3hAv8vq3QcoLK0gPMiPzk088xKw2+8qLeIJNuzNY8Tri/h9axYBvl68MrobT4zo5LTgcrRWEUH876p4fntwINf2jsHfx4sNe/P5+7S19P3vPF6cvZXMghKHnT8jv4ScwlKHPb/ISXnAyEvVRozntY04rWZ+d6SRFxGLfbt6DxO/XU9phZ3m4YG8c2MPOkRbP+unecNAJl3elYeGxDFleSqfLtlNen4Jr87dxlvzU7ikaxNu7tuSrs3Czuo85ZV2Vu46wPytmczfkkVyRgE+XjZu7deKewe1PWa6t4hDlRXBgZ3mcVRXa2s5C9Xru3jYlgBH0/YAIhYpq7DzzMxNfLxkNwAD20fyyjUJhAa65syA8ko7szak89EfO1mderD6692bh3Fz31YM7Rx12iNF+/MOsSA5i9+SM/kjJYfC0orq79lsUPWvUnRoAE+M6MiQTlGn7rkpLYD1X0PrARDeuqZ/PRGzWfed/lAvHB7ZaXU1ZyS7sJSeT88BYPk/Bjm0X662aXsAEReXkV/CnZ+vZtXuAwDcO6gt9w9q69JDvL7eXoyIb8KI+CasTTvI5MW7+HHdPlanHmR16hqiQgK4MbEF1/ZuTniQ3zE/e/ToyoLkLLakFxzz/YZBfgxoF8mA9pH0bxvJ6tQDPDFjI3sOHOKOz1YzsH0kT17aiRYNT7DEee4OmHItZG0B30C46GnoeYuZhEROV/Y28z6irbV1nIVF28yNGDtGh7hVcKkpjbyIONmKXbnc+flqsgpKCQ7w4aWruzG4Y2OryzojmfklfLYslS+W7Sa70NxLyd/Hi1HdmnJlz2ZszyxkfnIWf6RkU/Cn0ZVuMWEMbNeIge0j6dI09C/B7VBZJW/OT+HtBdsprzTw8/HiroGx/G1AawJ8j2oa3j4Ppt0MJQfByxfs5ebX2w6BS1+DYPd8bcUCv02CBf+FhBtg5BtWV3NGHpiaxPQ1e7ljQBseHRZndTk1UpPPb4UXEScxDIMP/9jFpJ82U2E3aN84mLdv7EErD9gwrbSikh/X7uejxTvZsDf/uI9pGORH/3aRDDw8utLgT6MzJ7I9q5DHv9/AHynm1M9WEUE8eWkn+reNgKVvwq//BMMOTXvCNZ/Cxukw50moLIXAhmaAibu41v6u4sG+vgU2fAMX/hv63md1NTVmtxv0/s8csgvLmDLuHBLbuNfKugovCi/iYnKLynho2lrmbskEYER8E569oguBfp515dYwDFbuPsBHf+xkQXIWbRsHc377E4+u1OR5f1y3n6d+3ERmQSn+lPFxoymck/+L+YD46+CSl8D38DB5xib4dhxkbDD/nHAjDJ0E/trDSU7i7X6Qvh5GT4G44VZXU2Mb9uZxyWuLCPLzZs3jF+Hn414TitXzIm7FbjfYlVOEj5cXzRsGWl1OrVuyPYf7p64hI78UPx8v/jG8A2MSW3jkom82m41eLcPp1bJ2Vya12WyMiG/CwPaRvPfTEs5PeoCE/BQqDRvL2z1IrxGP4XP0+jONO8K4efDbM/DHq7DmU9i1EC57F5r3qdXaxEPY7ZBtLg5JRDtrazlDVbOMEts0dLvgUlMKL+JUhmGwL6+EdWkHWbsnj/V7D7JuTx4FJWY/xBXdmzFxeBwR9f0trvTsVVTaeXVeCq/N24ZhQOvIIF6/trs2PzwLwdnrmLDzdvDaT4GtPuPL7mHR+i7EZf3B06M60/Po0OTjbw7/t70Ipt9h7lfz0VDoNwEGPgrerjmrSyySvxcqDpl9Uw1aWF3NGfH0LQGOpvAiDpVVUMr6vQdZm5bHuj0HWb83r7qx82h+Pl6UVdj5ZvUeZm9K5+GhcVzbuzneLjz75mT2HTzE/V8msXxXLgBX9WjGkyM7edxlIqda+yXMuNfsZYloT9DoKYzY6cuGn7ewJb2AK99ewtU9m/GP4R2PnW7esh+M/wN+ehjWfQkL/wcpc+Dy9yDSPX/DFgfI3mreh7dyy2BbUFJePXvRU7cEOJr+JZVaYxgGy3fmsir1AOsOh5V9eX9didXHy0b7qGC6Ngula7MwujYLpV3jYNbvzeOf0zewaX8+//xuA9NW7eGZUZ3p3NS9lreevSmDh75ey8HicoL8vHnmsi6MSmhqdVnuq7IC5jwBS143/9x+OFz2Dl4BIVwTARd2jOLZn7cwdWUaX63cQ3ZhGR+O7XXscwSEwuXvQPuh8OMD5hLw75wHFz4FvcdpSrUcNU3aPQPtku05VNgNWjQMPPGSAh5E4UVqxYGiMh76ei1zNmce83WbDdpE1qdrs1Dim4XRpVkoHaNDjp3qelj35g2YcXdfPlu6mxd+3cratINc+voibjynBRMuak9oPdf+baikvJL//ryFyYt3AdClaSivXZtASw+YTWSZQwfMGSDb55l/7v8QDHwMvI5czw8P8uPZK7tyefemXP/+MuZtyWRxSjbnxkb89fk6XQYx58D3d5rP+fNDsHWWOS02JNpJfylxSTmHw0vDWGvrOENVWwLUhUtGoPAitWDZjhzu+zKJ9PwS/Ly9uLBTY+IPj6p0bhpK/Ros7+7j7cXYvq0Y3iWap2duZsbafXy8ZDcz16fzz4s7MLJbE5dsdN2eVcg9X6xh035zmvBt/Vrx8NA4j2+ac6isZJgy2lyAzjcQRr1pho8T6NO6Idf3ac7HS3bzn583M+Oufsef3RQSDTd8C8vfg9n/B9vnwluJMOJV6HipA/9C4tKqLhu54ciLYRh1YkuAo2mqtJyxSrvB6/NSeGXuVuwGtI4I4rXrEuhUi7uY/pGSzf99v4EdWUUAnNM6nKdHdSa2ketMef1m1R7+7/sNFJdVEh7kxwtXxXN+XCOry3JvybPgm9ugrABCY2D0FxB96r1mcgpLGfD8fApLK3hldDdGdjvF5bqsZHNK9f61gA3+9vtpnUc80AsdoGAf3DoHYnqd+vEuZGd2Eef/bz6+3jaSHr/IbfcDq8nnt34tlDOSkV/C9e8v5aU5ZnC5onszfrinX60GF4C+sRH8fN95PDSkPf4+XizdkcuwVxby7KwtFJdVnPoJHKiwtIIHpibx4LS1FJdVkti6IT/fd56Cy9la/Jo54lJWAC36wu3zTztQNKzvz/iBbQB4blYyJeWVJ/+ByPbmh1XbiwADVn9ydrWLeyotMIMLQIT7XTZakGxeru/ZItxtg0tNKbxIjf22JZNhryxk6Y5cAv28efHqeF64Ot5h/9P4+3hz1/mxzJkwgEFxjSivNHhr/nYufPF3ft2Y7pBznsqGvXlc8upCpq/Zi5cNHrywHZ/d1ofGIZ67l4hTbPzOXDEXw9yb6MbvIOg4vSsncUvfVkSFBLD34CE+Pbzp5Un5+ME5d5rH67+C8r82mYuHq2rWDYqEeg2sreUM/H54P6O6MMuoisKLnLayCjtP/7iJmyevILeojI7RIfx4Tz8u797MKeePCQ/kg7G9eG9MT5qG1WPvwUPc/ukqbp28gjWpB6i0O/YKaHpeCR/9sZMr31rMJa8tYldOMU1CA5j6t0TuGdTWbad1u4ysZPj+LvM48W5zxVyf09tC4Gj1/LyZcJHZt/DavG0cLP7r1Py/aDXAvDxVkgdbfqzxOcXN5bjv4nSlFZUs2W5unVFXmnVBDbtymnbnFHHPlDWs25MHwNhzWzJxeBz+Pn+dNeRoF3ZsTN/Yhrw+L4X3Fu5g7pZM5m7JpEGgL+e1jWRAu0jOaxdRKzuqpueV8NP6/fy0fj8rD6+hUGV4lyj+c1kXwgJr/gErf1KSD19eD2WF0PI8GPzkWT3dFd2b8cHCnSRnFPDGbyn84+KOJ/8BLy/odr25Kd+az6DLlWd1fnEzVc26bjjTaOWuAxwqryQy2J8O0a7TC+hoCi9ySjPW7uOxb9dTWFpBaD1fnr+yKxd1irK0pkA/Hx4eGsfl3Zvy0pxt/J6cxYHicmas3ceMtea1605NQhjQzgwz3Vs0wNf79AYa9+cd4qf16fy0fn/1ok9VerZowPAu0QzrEkV0aL1a/3vVSYZhTl3O2QYhTeHKj8D77P5p8vay8ejwOG7+aAUfL97NmMSWxISfYuuJbteZ4WXHfDiYCmHNz6oGcSNuvMZL1aq657WNcMmZmI6i8CInVFxWwZMzNjF1ZRoAvVo24JXRCTQJc50P7dhGwbxxXXfKK+2sST3Igq2ZLNiaxYa9+WzcZ97enL+d+v4+9I1tyIB2jejfLoJmDY79IFNgsdAfr8DmH8xl2a/+BOrXztD3wHaR9I1tyB8pObzwazIvj044+Q80aGFePtq5AJKmwMBHaqUOcQPV4aWttXWcgQV1aEuAo2mqtBzXlvR87v5iDSmZhdhscPf5sdw3qC0+pzl6YbWsglIWbstiwdYsft9qjsocLbZRfQa0i6RRsD+/bExnderBY77fq+XhwNI5mqhQNeE6zI758OllYNjh4heh1621+vRVu+wC/HB3P7o0O8VsuHXT4NvbzFGXe9cesxieeCh7JTwTbW47ce8aCG9tdUWnLSO/hD7/mYvNBqv+eSHhQe59CVu7SssZyysu58sVqbw4eyulFXYaBfvz8jXdjr9aqQuLDPbn8u7NuLx7MyrtBhv25rFgqxlm1qQeICWzkJTMwurH22xHjbAosDjHwTRz9VzDbvab9Lyl1k/RuWkoo7o14bukffznp818Ma7PyYfWO1wC/qHmZaNdC6H1gFqvSVxMXpoZXLz9IMy9NmSctcGcbdmlaajbB5eaUngRDMNg2c5cvlyeyk8b0imrsAMwsH0k/7sq3u13ePb2shEfE0Z8TBj3DmpLXnE5i1KyWbA1k6yCUga0i2RYl2hNc3amilL4agwU50B0PFz8gsP2F/r7kPb8tD6dJTtymL81i/Pbn2QdHt96ZrPuyg/Mxl2FF89XdckovA14OX8CwpkyDIPPl5lLAVxeB/dOU3ipw7ILS/lm1R6mrkhjR3ZR9dfjooK56dyWXNMz5vjLq7u50EBfLu4azcVdtZeNZX5+GPatNtfUuPpTMzQ4SLMGgYzt25J3f9/Bf3/aQv+2kSef1p5wgxleNs+AQ89DvbATPrS4rILPl6bSrXkYvVqG137x4njV2wK4V7/Lil0H2JpRSD1fby5z0nIVrkThpY6x2w0WpWTz5YpUZm/KoLzSbHkK9PPm0vgmjO7dnPhmoXWqa12cbPWnsGoyYIMr3jcbZR3sroGxTF2RRnJGAd+s2sPVvWJO/OAmCdCoE2RuhA3fnLAPJ7OghFsnr2T9XnP5gGt7x/DosA4uv4Go/ImbzjSqGnW5NL5JnXzPKbzUEel5JUxbmcbUlWnsOXCo+uvxzUIZ3bs5I+Kb1GgDRZEzsm8NzHzQPD7/HxA72CmnDQ305Z4LYnl65mZemJ3MJfHRBPqd4P1us5mjL79MNC8dHSe8pGQWcNOHK9h78BBBft4UlVUyZXkaczZn8tTITgztrFE9t+GGM41yCkv5eb3Z73L9OXVzSr8+rTxYRaWd+clZfLkilXlbMqlagDY4wIfLEpoyuldzOjbRjCxxkuJcmDrGbI5sNwzOe9Cpp78xsQWTF+9iz4FDfLhoJ3dfcJIPq65Xw+zHzUtbGRuhcafqby3bkcO4T1aSX1JBy4aBTL65N5kFpTz6zTp2ZBdxx2erGdKpMf8e2Vl9VO4gx/3Cy7RVeyirtNO1WShdm4VZXY4lNA/QQ83dnMF5z/3GbZ+sZM5mM7j0atmAF66KZ/ljg/n3yM4KLuI89kpzZlFeqjkV9bK3nT4N2d/Hm4eGtAfg7QU7yC4sPfGDgyKg/TDzeM3n1V/+PmkvN36wnPySCro3D+PbO/vSMiKI3q3C+em+87jnglh8vGz8sjGDwS8s4ItlqdgdvG2FnIVDB6Ewwzxu6B7hxW43+GJZKgDX96mboy6g8OJxDMPgg0U7ue2TlezPK6FBoC+39WvFnAn9mXbHuVzRoxn1/Nyno148xG/PwI7fwDcQrvnspE2wjjSiaxO6NA2lsLSCV+duO/mDE24079d9iVFRylvzt3Pfl0mUVdoZ2imKL8adc8z01ABfbx68qD0/3tuP+JgwCkoreGz6eka/t5TtWYUnOIk4QlZBKZ8t3U1mwSk22aza06h+FAS4xy9zC1OySc0tJjjAhxHxTawuxzIKLx6kotLO499v5KkfN2EYZgPh0scG8c9LOhLbqO7seSEuZstMWPiCeXzpa8dcgnE2Ly8bE4fHAfDFslR2nCxUtLkAgqOhOIcvPn2PZ2dtAeDWfq144/ruBPge/5eAuKgQvh1/Lo9f0pF6vt4s35nLsFcW8sZvKZRX2mv97yTH+mn9fi56aQH//G4Dl7y6iKS0gyd+sBv2u3y+1GzUvaJ7sxP3bdUBCi8eIr+knFs+XsmnS3djs8E/hnfgP5d1sWTjRJFq2Skw/Q7zuM94l9jw8Nw2EVwQ14gKu8HzvySf+IHePpR1vgaAqB1fY7PBEyM68n+XdDzlDuLeXjZu6deKXx/oT/92kZRV2Hn+l2RGvLaItSf7MJUzdqCojHumrOHOz1dzoLgcP28vMgtKufqdJXy7es/xf8jNpknvzzvEnM3mZa66fMkIFF48QlpuMVe+tZjft2ZRz9ebt2/owbj+rTXdWaxVWghTb4DSfGieCBc9ZXVF1R4ZGoeXDX7ekM6q3bnHfUxmQQl3bzZ3ox7olcSHlzfj5r6tanSemPBAPr65Fy9f040Ggb5sSS/gsjf/4KkfN1FcVnHWfw8xzd2cwUUv/84Pa/fh7WXjngtiWfbYIAZ3aExZhZ0JX63lmZmbqPxz/1F1eHGPadJfLk/DbkDvVuG0bVy3R9Pr7piTh1iTeoBxn6wku7CMRsH+fHBTr1Pv32IVux1KDkJhJhRlQVEmFGYdOfbygRZ9zc3xamlzPrGIYcCMeyBrM9RvDFdNBm/XWYuifVQwV/WIYerKNP7z0xa+viPxmLB/ZCp0fVYHdKC7bTPnl8wF4mt8LpvNxqiEppzXNoKnZ25m+pq9fLBoJ79sTOeZy7rUuQ31alN+STlP/bCJaavMkZU2kUG8eHU34mPCAHj3xh68NGcrr81L4b2FO0nOKOS10QmEBh5+L1b1vLjByEt5pZ0vV5iNujec417bGDiCNmZ0Yz+u28eDX62ltMJOh+gQPhzb09pdj8uKYessc6+QoqzDwSTzyHFxNthP87fNRp3MpdlbDYCWfcG/bv+WwcFUc+dlvyDoONJcmdZVGQbMexoW/s8MpGNnQvNzrK7qLzLySxjw/G+UlNt5+4bu1WuzLN2Rw+2Hp0K3ighiWp8dRMx9wFw+/p5VZ72NwfzkTP4xfQN7D5rrLd2U2IKJwzucsIdGjm/Rtmwe/not+/JKsNngtn6tePCi9sd9HWeu28+D05IoKbfTKiKI98b0JLZhADwTBfZyuG+dUxZLPBuzNqRzx2eraBjkx+KJF3hkS0BNPr8VXtyQYRi8OX979fX6QXGNePXaBIKsWmSutNBcTn3xa2ZQOZWAUAhqBEGR5ghL1XFJHuz8HTLWH/t4mzc062kGmdYDoFkv8HHv/ZZOS2kBbJoBa6eYmwRW8faHuOEQf53ZVOrtQgOohgG/PAZL3zT/PPx/0HuctTWdxAu/JvPavBRaRQTx6wP9+Wn9fh6ato6ySjs9WjTgvTE9CfcpgxfaQ1kh3DwLWiSe9XmLSit4/pdkJi/eBZhbcrx+XYIa609DUWkFk37ezGdLzVGIFg0D+d9V8afcnmHjvjxu/2QVew8eItjfh/cuCeecmYPBJwAe2+/yO4jf+MEyFm7LZvzANjwyNM7qchxC4cWDw0tZhZ2J367nm8MNaLf0bcU/Lu5wygZChyjJg+XvwpI34dDhvoHQ5uY/7kGRR271Gx37Z59T7H5amAW7focdC2DnAjiw69jv+9Qzz1EVZqK6utWGaidlrzQD3Nop5khLefHhb9igZT9zobfMjUceX7+xuaBa/HXQuKMlJVezV8IP98GaT80/D3se+txubU2nUFBSzsDn55NTVEa/2AgWpWQDMKxzFC9d0+3Ib/Hf323+vbrdAKPeqLXzz0/O5O/T1pJdWEaArxf/GtGJa3rFqF/tBJbvzOXv09aSmmv+fzEmsQWPDos77Vk32YWl3PnZapbvymWQ92o+8P0fRuPO2Mb/4ciyz9qu7CIG/m8+Nhv8/tD5xIQHWl2SQyi8eGh4OVBUxh2frWLZzly8vWz8a0RHbkxs6fxCinNh2duw9G0oNfd1IbyNuWJq16trv7fhwG4zxOxYYH6wF2Ue+/16DaD7TTDgEfBz0/+ps7aagWXdVMjfe+TrDWMh/lroeg2ExZgjG+nrIOkLWD/N3JW5SnQ36HYddL4Sgho6t/6KMph+O2ycDjYvGPmGWYsb+HTJLv7v+yOB8LZ+rXhseIdjNyVNXQYfXgS+QfD35Fq9jJlZUMKDX61l4TYzOF3cNZr/XNalTu5XcyIl5ZX875dkPvhjJ4YBTUIDeO7KePq1jajxc5VV2Hlixkbqr3qTf/h+werg8+l47zcufdnuPz9t5t3fdzCwfSSTb+5tdTkOo/DigeFlZ3YRt0xewc7sIur7+/D6dQkMbN/IuUUUZcOS12H5e+YQOkBkHJz3d+h8uXNGPwwDMjcfCTO7FkFZgfm9Bq1gxCvmaIw7KM41N/5bOwX2rjry9YAw6HyFGVqa9Txxj0VFGaTMNoPM1l/Ma/cAXr7QbogZHmIvPPVI19kqPwRf3QTbfjHPfeUHZl+OmyivtDPitUUkZxTw+CUdjz+jyDDg9V7mUvKXvg7db6zVGux2g/cW7uD5X5KpsBs0DavHq9d2o0cL7VSdlHaQB79KYntWEQBX92zGPy/pSEjA2YW7be/fTNs93/JKxeXMaXwr747pYW3P4AmUlFeSOGkuB4rLeW9MTy7s2NjqkhxG4cXDwsvSHTnc8dkqDhaX0zSsHh+O7UX7KCdeGy9IN/tZVn545DJG4y7Q/+/Q4VJrrxVXVsDWn+HnR46MWCTcABc+BYEu+A9/+SHY/hus/QKSZx0JHDZvaHuhGVjaD6t5T09RDmz42gwy+5OOfD2wIXS5ygwy0TWfKXNKpQUw5VqzJ8cnAK75HNo6Z7PF2lRUWkFRaQWNTrYX0aKXYc4TEHMO3PqLQ+pISjvIvVPWkJpbjLeXjQcGt2X8wFhrLgtbzDAMXp2bwitzt2I3IDLYn2ev6MIFcbX04f3hUEhdwkTbvUw5dA4R9f1558buLhcYp6/ZwwNT19IkNICFj1zg0e8FhRcPCi/frNrDo9+uo7zSID4mjPfG9KBRsJM2e8vbY/6DvfoTczM9gCYJ0P9h8wPWla7Ll+TD3H/DivfMPwdFwrDnoNNl1tZZWgBpy2D3YvO2dxVUlh35flQXs1+ly5Vmb1BtyNhkhqN1Xx3ZtwXMHZwH/8s8Z20ozoXPrzT/Tn7BcN1Uc2aYpypIhxc7glEJd6902PTagpJy/vndBr5P2gdAYuuGvHRNN6JC69Ymj58s2cXjhy/njezWhCcv7URYYC2OIj7XBoqzSR/9C2NnlbElvQA/by+eHtWZq3vF1N55ztKVby1m5e4DTLiwHfcOcv0p3WdD4cVDwsvbC7bz35/NJckv7hLNC1fHO+e67ME0c5rrms+PjAzE9DFDS+wg1wotf5a6FGbcC9mHV05tNwwufgFCmzrn/MW5Zg27/zDDyv615ofd0YKjj1wWiursuFoqK2D7PDPIbP7h8DR1mzkSc8E/oEHLM3/uwkz4ZJTZPFyvAdzwLTTtXkuFu7AvRpsjfX3vhwufdNhpDMPgm9V7efz7DRSXVdIg0Jf/XRXPoA6ee8ngaCt25XLtu0upsBs8PLQ9dw6Mrd0TFOfCc4cvD07cSxEBPPjVWmZtTAfMLSD+eXEHyxunt6TnM/TlhXh72Vjy6AUnHxn0ADX5/HboeH9ubi7XX389ISEhhIWFceutt1JYePINygYOHIjNZjvmdscddziyTJdjGAaTftpcHVz+1r81r12b4JzgUpQN710AqyabwaXleXDTD3DLL+blAFcOLmCuJ3LHQhjwqNl/sfVneKOP2adjd8C+MgUZsOFbmPl3ePNc8x/EL681e4P2rTaDS1hzM6hc+jrcsxombIYhzzg2uIA5hbrdReYCcXevMBt5MWD9V/BaT/NSW1F2zZ/3YJo55J650ZztNPanuhFcwLwkCWafUqXjVsi12Wxc2aMZP97Tj05NQjhQXM6tH6/kXzM2UlJeeeoncGPpeSWM/2w1FXaDS7pGM35Am9o/SdWeRiFNwb8+Qf4+vHl9d+4fbI5sfLBoJ58s2V37562hzw9PB7+oY2OPDy415dCRl2HDhrF//37eeecdysvLufnmm+nVqxdffPHFCX9m4MCBtGvXjn//+9/VXwsMDDztURR3H3mpqLTzj+kbmLoyDYCJw+L4myP+5z2RaWPNGSMN25qb6NXCmhaWydxsrvK6Z4X555hz4NJXIbL9mT1fZQVkbYG9K2HPSkhdcmSFzqNFtIMW55qrBTdPNGcJuYp9STD3SXNEBszLPX3vhXPuBP/6p/75nO3w8aWQv8ecFj/mO2joxPen1SrL4cUO5npG106F9kMdfsrSikqem5XMB4t2AtAhOoTXrk0gttFp/PdyM6UVlVzzzlKS0g4SFxXMt3ee65jNB9d8Bt/fBa0Hwpjvj/nWB4t28tSPm/Dz9uKb8edatmJ5UWkFff4zl8LSCj6/rQ99Y2s+s8rduMRlo82bN9OxY0dWrFhBz549AZg1axbDhw9nz549NGly/K28Bw4cSLdu3Xj55ZfP6LzuHF5Kyiu5/8skZm1Mx8sG/728q3OvvW78DqbdZDaP3v6bYxo8nc1eCSs+MD+wywrB28+cHdXvgVPPwsnbeySo7F1lfvCXF/3pQTZzBKVFXzOwNE+svd4VR9r+G8z515Hm3qBGMOBhc8r5iV6X9A3w6WXmVPWGseY/+qHNnFWx6/jlH+bIWtwlMPpzp532ty3mmjA5RWXU8/XmP5d35rIEz3r9J367jinL0wit58uMu/vSomGQY040+3H44xXofTsMf/6YbxmGwd8+XcWvmzJoHh7Ij/f2O+uZTWfii2WpPDZ9Pa0igpg7YcCxU/c9lEtcNlqyZAlhYWHVwQVg8ODBeHl5sWzZspP+7Oeff05ERASdO3dm4sSJFBcXn/CxpaWl5OfnH3NzR4WlFdwyeQWzNqbj5+3Fm9f3cG5wKcqBmQ+ax+dN8IzgAub07T63w51Loe1FZrPs/P/AO/0hbfmRx5UWmGvILHwRvrweXoiDlzrCV2Ng8atmD0t5kTlS0ao/9Jtg/ub9yC64YxEMe9acHuwOwQWgzfkw7je48iNzinlRJvz0d3ijtzl9+8+X2PasgskXm49r3MVcabYuBhc4culo6yxzQUUnOT+uET/fdx59YxtyqLySB6au5c35KXhK2+IXy1KZsjwNmw1evTbBccEFjlw2avjXBlibzcbzV8bTNKweqbnFTPxmvdNfY8Mw+HyZednq+j7N60RwqSmHrSuenp5Oo0bH/kPu4+NDeHg46enpJ/y56667jhYtWtCkSRPWrVvHI488QnJyMt9+++1xHz9p0iSefNJxjXPOkFtUxtiPlrNuTx5Bft68N6Yn5zp7iPDnh8y9hxp1hP4POffczhAWA9d9ZX4w//yIuWHgBxeZ66EcTDUvMfGnf6Bs3uaqtU17QNOe5porEe08ZzVfLy9zfZ4OI8wepwXPwYGd8PUtEP0KDH7SDDk7F8KU0ebIVbNecP00195bydEadTDfD3tXmosKnnu3804dEsCnt/Th2V+28M6CHTw3K5msglL+7+KObv0Bt2r3AZ6YsQGAh4a0d/xmlVXh5QQzxkIDfXn9ugSuensJM9fv55xlDbnRiZshJqUdZOO+fPx8vLiiex39JeEUahxeHn30UZ599tmTPmbz5s1nXNDttx9ZTrxLly5ER0czaNAgtm/fTps2f722PnHiRCZMmFD95/z8fGJiXKjH4BT2HTzEjR8sY3tWEQ0CfZl8c+/qHVGdZtMM80Pd5m2ujOqp+wbZbOaU5DYXmEP/a78wf3uuEtIMmh0VVKLjzY0QPZ23r7n/UPy1sPQtczh9/1r4dJR5OWzvKqgoMUecRk85vd4YT5dwgxle1nwKiXc5tZHdy8vGxGEdaBQcwFM/buKjP3aRU1jG/66Kx8/HtffnOZ7M/BLGf7aK8kqD4V2iHNOge7TKcjOkw0mnuyc0b8AjQ+N45qfNPPXjJro3D6NTE+f0v3y+zGzUvaRrNA2CHLzIpJuqcXh58MEHGTt27Ekf07p1a6KiosjMPHYZ94qKCnJzc4mKijrt8/Xp0weAlJSU44YXf39//P3d88M2JbOQMR8sY19eCdGhAXx6ax/nN+EV58LMw+Gv3/11Y9ZIYDhc9pa5cFvqUvM36WY9Ifj035ceyb8+DHgIet4Mv/8PVrxvXi4Dc8r5VZPBVzMeAHPEatbEww3cq83Q62S39mtFRH0/HvxqLTPW7iO3qIy3b+xBfas2aD0DZRV2xn++msyCUto1rs/zV8Y7fnrygV3msgG+QRB8/N7LKred14qlO3KYuyWTu79Yww/39HP463uwuIwf1ppr/Fzfx7V3urZSjf8rREZGEhl56iG9xMREDh48yKpVq+jRw/wfe968edjt9upAcjqSkpIAiI6OrmmptW57ViGtGgbVyvDsuj0HGfvRCnKLymgdGcSnt/ahaZgFS1P//LA5cyIyztwbqC5pdZ55k2MFRcCw/8I5d5iLFPrXh0FP1P6eVe4sINTscVr3pTn6YkF4ARjZrSkNAv2447NVLErJ5rr3lvLh2F5E1HePX+j+/eNGVu0+QHCAD+/c2JMgZwSv7K3mfUTsKVcHt9ls/O+qeC5+dSE7s4t47Nv1vDK6m0MD1jer91JaYadDdAjdm4c57DzuzmFjjB06dGDo0KGMGzeO5cuX88cff3D33XczevTo6plGe/fuJS4ujuXLzcbJ7du389RTT7Fq1Sp27drFjBkzGDNmDP3796dr166OKvW05BWXc+GLC+j9nzk8MDWJ6Wv2kFVQekbPtXh7Nte+u5TcojK6NA1l2t8SrQkum380N/ezecGoNz33cpGcmQYtYcTLcNHTCi7HU9W4u+EbKDvxpAJH698ukinjziE8yI91e/K48q3FpOVaV8/pmroilc+WpmKzwSuju9EqwkmXaKvCy3GadY+nQZAfr12XgLeXjRlr9/HlijSHlfbnRl2rF8lzZQ69QPr5558TFxfHoEGDGD58OP369ePdd9+t/n55eTnJycnVs4n8/PyYM2cOF110EXFxcTz44INcccUV/PDDD44s87RszSwgwNeb7MIypq/ZywNT19LrmTkMf2Uh//15C4u3Z1NWcepF0H7ZmM7YD1dQVFZJYuuGfDGuDw2t+C2pOBd+fMA87nuf2ZQqIqevRV8z4JXmmysYWyg+Joyv7zB/CdqVU8zlby1m0z7XnXmZlHaQ//vOXPp/wuB2tbdf0enIPrw2U0S70/6RHi3CeWiIuT7Uv2ZsZPN+x7y2S3bksCOriCA/b0YlOGlVcDel7QFqoKzCzqrdB/h9Wxa/b81i45/+cQj08yaxdUP6t4ukf7tIWjYMPCY5f7UyjUe/WYfdMFdMfNVZq+YezzfjzJVWI9rD335XL4PImVjwPPz29HEXO7NCRn4JN324nC3pBQT7+/DeTT05p3VDq8s6RlZBKSNeW0R6fgkXdWzM2zf0cO5MqfcvhD3LzWUCOl9+2j9mtxvc8vEK5idn0ToyiB/u7lfrl7nu+nw1M9fv5/o+zXnmslrag8yNuMQidVZx5iJ1WQWlLErJ4vet2SzclkV2Ydkx348Jr0f/tmaQ2ZFVxLOzzOX+r+7ZjP9c1gUfb4tmBmyZCV9eZ14uunW22awqIjWXuwNeTQAvH3goxSWmkOcdKmfcJytZvjMXPx8vXh3djaGdre8ZBCivtHP9e8tYviuXNpFBfHdXX4KduQCcYcCzLaHkoLk+Uw03Kc0tKmP4KwtJzy/hsoSmvHh17TUYZxaUcO6keVTYDX669zw6NnGvRVZrg0ssUlcXRAb7c1lCM166phvLHxvMj/f04+Gh7TmndTi+3jbScg/x+bJU/vbpqurgcnv/1jx7RVfrgsvRl4vOvUfBReRshLeGyA7m7JVts62uBoDQer58cktvhnRqXD2b57Ol1u/TA/DMzM0s35VLfX8f3h3T07nBBaA4xwwu2CC85lOyw4P8ePVas/9l+pq9TFu5p9ZK+2pFGhV2g+7Nw+pkcKkphZda4uVlo3PTUO4cGMuXtyeS9PhFfHBTT25KbEGriCC8bPDI0DgeG27xTqWzJkJhhnm9d+Bj1tUh4inihpv3W2ZaW8dRAny9efP6HlzbuzmGAf/8bgMvz9lq6Wq8X6/aw+TFuwB46ZputIm0YL2gqmbd0BjwCzyjp+jdKpwJF5r9Mo/P2MDWjIKzLqvSbjBludkIfIMTF8NzZ+6zIICbCfL3YVCHxtVb2JdWVOLvY/HKrMk/m1M7bV4w8k31uYjUhriLYeELkDIHKkpdZtaet5eN/1zWmchgf16du42X52wjq6CUf4/sjLeTV+NdvyePx6avB+C+QW25sKMTG3SPdoqVdU/X+AFtWLojh4Xbsrnz89XMuLvvWW0gOT85k70HDxEW6MvwLq5xic/VaeTFSSwPLocOwA/3m8eJd0FML0vLEfEY0QkQHG1un7Dzd6urOYbNZmPChe14alRnbDZz5da7Pl9NYWmF02rIKijlb5+upKzCzqC4Rtw36OyCw1mpXuPl9GcaHY+Xl42XrulGo2B/UjILefz7jTV+jpLySpZsz+GFX5P51w/mz1/Vo5l1kzjcjEZe6opZj0Fhurkb8Pn/sLoaEc/h5QXth8HKD81LR20vtLqiv7jxnBY0DPKr3rV+zQsHeGx4By6Nb+Kwy9iVdoOpK9J4/pctHCgup3VEEC+N7mbtHkzVIy+xZ/1UEfX9eWV0Ate/v5SvV+0hsXVDruhx4n2IKirtbNiXzx8p2SzZnsOKXbmUHrW8RligLzee0/Ks66orFF7qgq2/mPv4YDt8uciCBfFEPFncxWZ4Sf4ZLn7xlCu3WmF4l2gaBvnx0NfrSM0t5r4vk5iyPJUnL+1M+6jgWj3Xqt0H+NeMjazfmwdA20b1efvGHoQ4u0H3z3KqwsvZjbxUSWzTkPsHt+PF2Vv553cbiI8JJbaR+VoahsHWjEIWb8/mj5Qclu3MoaDk2BGvyGB/+rZpyLltIhjYPpJGIbqUf7o0VdrTHToIb54DBfsh8W4Y8ozVFYl4nopSeK4NlBXAbXNdehZfSXkl7/6+gzd+S6G0wo63l42bElty/4VtzzpcZBaU8OzPyXyz2pyFE+zvwwMXtuPGxBb4WjXDskpFKTwTBYYdHkyutb3MKu0GYz5cxh8pObRvHMzNfVuyeHsOi7fnkF147CrsIQE+nNO6IX1jI+gb25A2kfW1iu5RtM6LwssR390FSZ+Z0wLvWHTGHfYicgrTxsLG6dBvAgx+wupqTiktt5inZ27il40ZgHkZ5LHhcVyW0LTGH6jllXY+XryLl+dsq+6nuapHMx4eGkdksGs0MJO5Bd7sA37BMDGtVncCzyooZdgrC/8SVgJ8vejVMpy+sRGc26YhnZqEOr1Z2p3U5PNbl4082bbZZnDBBiPfUHARcaS4S8zwkvyTW4SXmPBA3rmxJwu2ZvGvGRvZmV3EhK/W8sWyVJ4c2YlOTUJP63kWbcvmXz9sJCWzEID4ZqH869JOJDS3fsG+Y1Q367at1eAC5uWf169LYMLUJJqE1ePc2Aj6tmlIt+Zh1k/W8FAKL56qJA9m3GsenzMeWiRaW4+Ip4sdbK60m7UFcrZDw5ovgmaFAe0imXX/eXywaCevzU1h5e4DjHhtETec04IHL2xPaODxLyWl5RbzzMzNzNqYDkDDID8eHtqeq3rEWNuUeyJHhxcHOKd1QxZPHOSQ55a/cr2uMjl7hw7A51dDwT5o0Aou+D+rKxLxfPXCoGU/89iFFqw7Hf4+3tw5MJa5Dw7g4q7R2A34ZMluLnhhPl+tSMNuP9JdUFJeyctztjL4xQXM2piOt5eNsee2ZN7fB3JNr+auGVwAcqo2ZLRwqrbUGoUXT5O/Hz66GNKWQkAoXPmBLheJOEvcJeZ98k/W1nGGmoTV443ruvP5bX2IbVSfnKIyHv5mHZe/tZj1e/KYtSGdwS8u4OU52yitsHNO63Bm3tuPf13aidB6Fs8kOpVaWuNFXIMadj1Jznb4dBQcTIX6UXDjt9C4k9VVidQdeXvgpU6ADf6+DepHWl3RGSuvtDP5j128PGcrRWWVx3wvOjSAx4Z34JKu0e4xW8Yw4L/NoTQfxi+Bxh2trkiOQxsz1kX7kuCDi8zgEt4abv1FwUXE2UKbQXQ8YMDWWVZXc1Z8vb0Y1781v/19IKO6NQHAz9uLu85vw9wHBzDCgQvc1brCTDO42LzMfx/F7alh1xPs/B2mXGeuMRHVFW741q1/4xNxa3GXwP615qWj7jdaXc1ZaxQSwMujExg/MJbgAB+ahLnhIpdVl4zCWmhPNw+hkRd3t2kGfHaFGVxangdjZyq4iFip/eFdprfPg7Iia2upRe2jgt0zuMBRK+uqWddTKLy4s1WTYdpNUFkGHUbA9V9DQB3r8xFxNY07QVhzqCiB7b9ZXY3AUXsaqVnXUyi8uCPDgN//Bz/cZy513f0muOpjDYeKuAKbze1nHXkcB6/xIs6n8OJu7HaYNRHmPWX++by/w4hXwEurOIq4jKpLR8k/Q2XFyR8rjlc18tJQ4cVTKLy4k8pymP43WPaW+eeh/4VB/1frS12LyFlqngj1GsChXEhbZnU1dVv5IXMWJuiykQdReKmJ2U/AjgXWnLusCKZcC+u/Mpcgv/w9c9l/EXE93j7Qbqh5rEtH1srdARjmop1BEVZXI7VE4eV0pcyFP16GTy6Fb2+Hwiznnbs4Fz4ZBSmzwaceXPsldL3aeecXkZqrunS05UezT02scfTKuhql9hgKL6erWU/oNQ6wwbqp8HpPWPWx2YPiSHl74aNhsGc5BITBTTOg7YWOPaeInL02F4C3PxzYBZmbra6m7tJMI4+k8HK6AkLh4v/BbXMhqguUHIQf7jWDhSP+YSrOhQXPwzv9zV1qg5vALbMgpnftn0tEap9/fWhzvnmc7F4bNXqU6mbdWGvrkFql8FJTzXrAuPkw5D/gG2RugPh2P5jzLygrPvvnP7ALfnrY3B/lt6ehOBsi2pvL/TfqcPbPLyLOU33pSOHFMtqQ0SMpvJwJbx9IvAvuXm6u52CvgEUvwZvnwLbZZ/ac+9bAtJvh1QRY/g6UF5sjPJe/D+P/MBe9EhH30n4YYDP//87fZ3U1dY9hQE6Keazw4lEUXs5GaDMY/TmMngIhzeDgbvj8SvjqJsjff+qfNwwz7Ey+BN4dCBu/NReda3MB3Pgd/G0hdL0KvF18q3kROb76jaBZL/NYs46cr2A/lBWCzRsatLS6GqlFCi+1IW443LUMEu82/yfZ9B280RuWvQv2yr8+vqIMkr6At841w86uheb0567XwB2L4Mbp5rVydcaLuL+4i817XTpyvqpLRuGtwMfP2lqkVim81Bb/+jDkGbh9PjTtYW6//vND8P5gc4dZgJI8WPQyvNIVvhsPmZvAr74Zeu5bC5e/a14qEhHPURVedi40/w0Q59HKuh7Lx+oCPE50V7h1Nqz8EOb+G/atNi8JtRsGO383d38GqB8F59wBPW6GemFWViwijhTR1vzwzNkGKXOg8xVWV1R3ZGs3aU+lkRdH8PKG3uPg7hXQ6XKzjyV5phlcIuNg5Btw/zro94CCi0hdoEtH1tBMI4+lkRdHCo6Cqz6ChOth43TocCnEXgheyowidUrcxeYK3dtmmz1v6r9wjuqZRhp58TQKL84QO9i8iUjd1LQnBDWCokzYvcicUSiOVVYEeWnmsUZePI6GAEREHM3L6/CaL+jSkbPkbDfvAxtCYLi1tUitU3gREXGGqr6X5J+1UaMzVPW7aKaRR1J4ERFxhlYDzC1F8vfC/iSrq/F8mmnk0RReREScwTcAYgeZx7p05Hg5Ci+eTOFFRMRZqqdMa6sAh9M0aY+m8CIi4ixtLzK3EMncCLk7ra7Gc9ntkK0NGT2ZwouIiLMEhkOLc81jbdToOPl7oeIQePlCWAurqxEHUHgREXEmXTpyvOoNGVuDt5Yz80QKLyIiztR+uHmfuhiKc62txVNpZV2Pp/AiIuJMDVpA4y7mnmdbZ1ldjWfal2TeN+pgaRniOAovIiLOFnd49EVTph0jbal5H9PH2jrEYRReREScrerS0fZ5UH7I2lo8TWEm5O4AbNCsl9XViIMovIiIOFt0PIQ0g/Ji2Par1dV4lrRl5n2jDlAvzNJSxHEUXkREnM1mg65Xm8crP7S2Fk9TFV5ieltbhziUwouIiBV6jAVssGP+kR2Q5eylVoWXc6ytQxzKYeHlmWee4dxzzyUwMJCwsLDT+hnDMHj88ceJjo6mXr16DB48mG3btjmqRBER6zRoYa64Cxp9qS3lJUc2vWyuZl1P5rDwUlZWxlVXXcX48eNP+2eee+45Xn31Vd5++22WLVtGUFAQQ4YMoaSkxFFliohYp9et5v2az9S4Wxv2rYHKMghqBA1aWV2NOJDDwsuTTz7JAw88QJcuXU7r8YZh8PLLL/PPf/6TkSNH0rVrVz755BP27dvHd99956gyRUSsEzsYQptDyUHYON3qatxf1RTp5n3MviLxWC7T87Jz507S09MZPHhw9ddCQ0Pp06cPS5YsOeHPlZaWkp+ff8xNRMQteHlDz7Hm8Yr3LS3FI6jfpc5wmfCSnp4OQOPGjY/5euPGjau/dzyTJk0iNDS0+hYTE+PQOkVEalXCGHMDwb2rjqwMKzVnGEdmGjVXePF0NQovjz76KDab7aS3LVu2OKrW45o4cSJ5eXnVt7S0NKeeX0TkrNSPhI4jzeOVH1hbizvL3gaHcsEnAKK6Wl2NOFiNttt88MEHGTt27Ekf07p16zMqJCoqCoCMjAyio6Orv56RkUG3bt1O+HP+/v74+/uf0TlFRFxCr1thw9ew/mu46GkICLW6IvdT1e/StAf4+FlbizhcjcJLZGQkkZGRDimkVatWREVFMXfu3Oqwkp+fz7Jly2o0Y0lExO00T4TIDpC1GdZ+CX3+ZnVF7qe630VTpOsCh/W8pKamkpSURGpqKpWVlSQlJZGUlERhYWH1Y+Li4pg+3eywt9ls3H///Tz99NPMmDGD9evXM2bMGJo0acKoUaMcVaaIiPVstiPTpld8YPZvSM1UzzRSv0tdUKORl5p4/PHH+fjjj6v/nJCQAMBvv/3GwIEDAUhOTiYvL6/6MQ8//DBFRUXcfvvtHDx4kH79+jFr1iwCAgIcVaaIiGvoeg3MfgKyk2H3H9Cyn9UVuY+ibMhJMY+1GWOdYDMMz4r4+fn5hIaGkpeXR0hIiNXliIicvh/ug1WTodPlcNVHVlfjPrbMhC+vg8g4uGuZ1dXIGarJ57fLTJUWEanzeh6+dLT5ByjIsLYWd6LNGOschRcREVcR3dW87GEvhzWfWF2N+9DidHWOwouIiCupGn1Z9THYK62txR1UlJp7GoGadesQhRcREVfS6TKo1wDy0mDbr1ZX4/r2JUFlKQRGQPiZrTMm7kfhRUTElfgGQMIN5vEKrbh7SkdPkdZmjHWGwouIiKvpcbN5nzIHDuyytBSXp8Xp6iSFFxERV9OwDbS5ADBgpaZMn5A2Y6yzFF5ERFxRVePumk/NplT5q5ztUJwN3v4QHW91NeJECi8iIq6o3VAIaQrFObBphtXVuKbqzRi7g4826K1LFF5ERFyRtw90v8k8XqnG3eNKPRxe1O9S5yi8iIi4qu5jwOYNqUsgY6PV1bge9bvUWQovIiKuKiQa4i42jzVt+ljFuZC91TzWyEudo/AiIuLKet1m3q+bCqUF1tbiSqpGXSLaQWC4tbWI0ym8iIi4slb9oWFbKCuEdV9ZXY3rqO530WaMdZHCi4iIK7PZoOct5vHKD821TQTSlpv32oyxTlJ4ERFxdd2uBZ96kLHhyId2XVZRBvtWm8dq1q2TFF5ERFxdvQbQ+QrzWNOmYf9aqCiBwIbQMNbqasQCCi8iIu6g1+FLRxunQ1GOtbVYLe2o9V20GWOdpPAiIuIOmvaA6G5QWQZJn1ldjbW0OF2dp/AiIuIueh3e72jlh2C3W1uLVbQZo6DwIiLiPjpfCf6hcGAXbJ9ndTXWyN0BRVng7WeOREmdpPAiIuIu/AKh23XmcV1t3K0adWmSAL4B1tYillF4ERFxJ1Vrvmz9BfL3W1uLFdTvIii8iIi4l8h20DwRjEpY+4XV1Tif+l0EhRcREffTfYx5v/rTutW4W5wLWVvMY4281GkKLyIi7qbjSPAPgQM7Yfciq6txnj0rzPuGsRAUYW0tYimFFxERd+MXBF2uNI9Xf2JtLc6kfhc5TOFFRMQdVV062jTDvJxSF1T1uyi81HkKLyIi7ii6GzTuApWlsH6a1dU4XmU57F1lHqtZt85TeBERcUc225HRl1UfmyvPerL968zNGOs1gIZtra5GLKbwIiLirrpeBd7+kLkR9q22uhrHOnozRi99dNV1egeIiLireg3MmUfg+Y27ataVoyi8iIi4s6pLR+u/htJCa2txFG3GKH+i8CIi4s5a9oPw1lBWCJu+s7oaxziwCwozwMvX3NNI6jyFFxERd2azQcKN5rGnXjqq3oyxG/jWs7QUcQ0KLyIi7q7bdWDzNj/kM7dYXU3tU7+L/InCi4iIuwuOgnZDzeM1n1pbiyOo30X+ROFFRMQTVDXurp0CFWXW1lKbDh2EzM3msUZe5DCFFxERTxA7GIKjoTgHkn+yupras2cFYJhNyfUbWV2NuAiFFxERT+DtY/a+gGc17qrfRY5D4UVExFMk3GDeb58HB1OtraW2aDNGOQ6FFxERTxHeGlr1BwxY87nV1Zw9bcYoJ6DwIiLiSbrfZN6v+QzsldbWcrbS10N5MQSEQkR7q6sRF6LwIiLiSeIugYAwyN8D23+zupqzc/QlI23GKEfRu0FExJP4BkD8aPN49cfW1nK21KwrJ6DwIiLiaaq2C0j+CQqzrK3lTGkzRjkJhRcREU8T1Rma9gB7hblonTtKXw8F+8HbD5p0t7oacTEKLyIinqhqxd3Vn5ijGO5m3VTzvt1Q8Au0thZxOQovIiKeqPMV4BsEOduO9I64C3slrP/aPK7q3xE5isPCyzPPPMO5555LYGAgYWFhp/UzY8eOxWazHXMbOnSoo0oUEfFc/sHQ+TLz2N1W3N0xHwrToV4DiL3Q6mrEBTksvJSVlXHVVVcxfvz4Gv3c0KFD2b9/f/VtyhQ3vV4rImK1hMOXjjZOh5I8a2upiapLRp0uBx8/a2sRl+TjqCd+8sknAZg8eXKNfs7f35+oqCgHVCQiUsfE9DYXd8tONi/D9LrV6opOrbQQNv9gHuuSkZyAy/W8zJ8/n0aNGtG+fXvGjx9PTk7OSR9fWlpKfn7+MTcREQFstmMbd93BlpnmqrrhraFZL6urERflUuFl6NChfPLJJ8ydO5dnn32WBQsWMGzYMCorT7zE9aRJkwgNDa2+xcTEOLFiEREXFz8avHxhfxLsX2d1Nae27kvzvus1ZvgSOY4ahZdHH330Lw21f75t2bLljIsZPXo0l156KV26dGHUqFH8+OOPrFixgvnz55/wZyZOnEheXl71LS0t7YzPLyLicYIiIO5i83jNp9bWcioF6WazLkDXqy0tRVxbjXpeHnzwQcaOHXvSx7Ru3fps6vnLc0VERJCSksKgQYOO+xh/f3/8/f1r7ZwiIh6n+xjY9J3ZCHvhv8G3ntUVHd/6aWDYoVlv87KRyAnUKLxERkYSGRnpqFr+Ys+ePeTk5BAdHe20c4qIeJzW50Noc8hLNZthXXVUY+3hWUbx11hbh7g8h/W8pKamkpSURGpqKpWVlSQlJZGUlERhYWH1Y+Li4pg+fToAhYWFPPTQQyxdupRdu3Yxd+5cRo4cSWxsLEOGDHFUmSIins/LCxJuMI9dtXE3YyNkrDf7czpdbnU14uIcFl4ef/xxEhISeOKJJygsLCQhIYGEhARWrlxZ/Zjk5GTy8sy1B7y9vVm3bh2XXnop7dq149Zbb6VHjx4sXLhQl4VERM5WwvWADXYthOwUq6v5q+rtAIZAYLi1tYjLsxmGO256cWL5+fmEhoaSl5dHSEiI1eWIiLiOz6+Cbb9C++Ew+gvXmc1jr4SXOkPBPrj6E+g40uqKxAI1+fx2qanSIiLiQIOfNC/LJP9krrrrKnYtNINLQKi5EaPIKSi8iIjUFY07wnkTzOOfH4biXGvrqbLuK/O+02XgozYBOTWFFxGRuuS8B80tA4qy4Jd/WF0NlBXDpu/N467aDkBOj8KLiEhd4uMPI18HbLD2C0iZa209yT9BWSGENYfm51hbi7gNhRcRkbompjf0vt08/vF+czNEq6zVdgBScwovIiJ10aDHITQGDqbCb89YU0NhJmyfZx7rkpHUgMKLiEhd5F8fLnnZPF76FuxZedKHO8SGb8CohKY9ICLW+ecXt6XwIiJSV7UdbF6uwYAZ90BFmXPPX33JSKMuUjMKLyIiddmQSRDYEDI3waKXnHferGTYnwRePtBZ2wFIzSi8iIjUZUENYdhz5vHvz0PmFuect2rUJXYwBEU455ziMRReRETqus5XQNshYC83Lx/Z7Y49n90O66eZx121g7TUnMKLiEhdZ7PBJS+CXzDsWQ4r3nfs+VIXQ14a+IdA+2GOPZd4JIUXERGB0GYw+AnzeO6TcDDNceequmTU8VLwree484jHUngRERFTz1uheaK54u2PD4Bh1P45yg9pOwA5awovIiJi8vKCEa+Ctx+kzD7Sl1Kbkn+G0nxzgbwWfWv/+aVOUHgREZEjItvBgIfN458fgaLs2n3+qh2ku1xlhiWRM6B3joiIHKvv/dC4MxzKhVmP1t7zFmWbIzqgWUZyVhReRETkWN6+cOlrYPMyLx1t/aV2nnfDt2CvgOh4aBRXO88pdZLCi4iI/FXT7nDOnebxjxOgtODsn3OdtgOQ2qHwIiIix3f+P6BBS8jfA3OePLvnyt4Ge1eBzRu6XFkr5UndpfAiIiLH5xcII14xj1e8D6lLz/y5qhp121wA9RudfW1Spym8iIjIibUeCAk3AAZ8Mgq+vB6SpkBx7uk/h2HAuqnmsRp1pRb4WF2AiIi4uIuehvT1sH8tbPnRvNm8oWVfiLsE4i42V+g9kdSlcHA3+NU3HytylhReRETk5Oo1gNsXQPo62DITNv8ImRth5+/m7eeHIbqbGWQ6XAKRceZ+SVWqGnU7XGpeihI5SzbDcMT6z9bJz88nNDSUvLw8QkJCrC5HRMQz5e4wg8yWmYd7YY76KAlvfXhE5hKI7govtIeSPBjzvXkZSuQ4avL5rfAiIiJnpzDTXPZ/y0zY8RtUlh35nn+IuR1AcBN4YAN4eVtXp7i0mnx+67KRiIicnfqNoMdN5q20AFLmmJeWtv1qBheArlcruEitUXgREZHa4x8MnS4zbxVlsGshZG+F7jdZXZl4EIUXERFxDB8/iB1k3kRqkdZ5EREREbei8CIiIiJuReFFRERE3IrCi4iIiLgVhRcRERFxKwovIiIi4lYUXkRERMStKLyIiIiIW1F4EREREbei8CIiIiJuReFFRERE3IrCi4iIiLgVhRcRERFxKx63q7RhGADk5+dbXImIiIicrqrP7arP8ZPxuPBSUFAAQExMjMWViIiISE0VFBQQGhp60sfYjNOJOG7Ebrezb98+goODsdlstfrc+fn5xMTEkJaWRkhISK0+t6fQa3Ryen1OTa/Rqek1OjW9Rifniq+PYRgUFBTQpEkTvLxO3tXicSMvXl5eNGvWzKHnCAkJcZn/2K5Kr9HJ6fU5Nb1Gp6bX6NT0Gp2cq70+pxpxqaKGXREREXErCi8iIiLiVhReasDf358nnngCf39/q0txWXqNTk6vz6npNTo1vUanptfo5Nz99fG4hl0RERHxbBp5EREREbei8CIiIiJuReFFRERE3IrCi4iIiLgVhZfT9MYbb9CyZUsCAgLo06cPy5cvt7okl/Gvf/0Lm812zC0uLs7qsiz1+++/M2LECJo0aYLNZuO777475vuGYfD4448THR1NvXr1GDx4MNu2bbOmWIuc6jUaO3bsX95XQ4cOtaZYC0yaNIlevXoRHBxMo0aNGDVqFMnJycc8pqSkhLvuuouGDRtSv359rrjiCjIyMiyq2PlO5zUaOHDgX95Hd9xxh0UVO99bb71F165dqxejS0xM5Oeff67+vru+hxReTsPUqVOZMGECTzzxBKtXryY+Pp4hQ4aQmZlpdWkuo1OnTuzfv7/6tmjRIqtLslRRURHx8fG88cYbx/3+c889x6uvvsrbb7/NsmXLCAoKYsiQIZSUlDi5Uuuc6jUCGDp06DHvqylTpjixQmstWLCAu+66i6VLlzJ79mzKy8u56KKLKCoqqn7MAw88wA8//MC0adNYsGAB+/bt4/LLL7ewauc6ndcIYNy4cce8j5577jmLKna+Zs2a8d///pdVq1axcuVKLrjgAkaOHMnGjRsBN34PGXJKvXv3Nu66667qP1dWVhpNmjQxJk2aZGFVruOJJ54w4uPjrS7DZQHG9OnTq/9st9uNqKgo4/nnn6/+2sGDBw1/f39jypQpFlRovT+/RoZhGDfddJMxcuRIS+pxRZmZmQZgLFiwwDAM8z3j6+trTJs2rfoxmzdvNgBjyZIlVpVpqT+/RoZhGAMGDDDuu+8+64pyQQ0aNDDef/99t34PaeTlFMrKyli1ahWDBw+u/pqXlxeDBw9myZIlFlbmWrZt20aTJk1o3bo1119/PampqVaX5LJ27txJenr6Me+p0NBQ+vTpo/fUn8yfP59GjRrRvn17xo8fT05OjtUlWSYvLw+A8PBwAFatWkV5efkx76O4uDiaN29eZ99Hf36Nqnz++edERETQuXNnJk6cSHFxsRXlWa6yspIvv/ySoqIiEhMT3fo95HEbM9a27OxsKisrady48TFfb9y4MVu2bLGoKtfSp08fJk+eTPv27dm/fz9PPvkk5513Hhs2bCA4ONjq8lxOeno6wHHfU1XfE/OS0eWXX06rVq3Yvn07jz32GMOGDWPJkiV4e3tbXZ5T2e127r//fvr27Uvnzp0B833k5+dHWFjYMY+tq++j471GANdddx0tWrSgSZMmrFu3jkceeYTk5GS+/fZbC6t1rvXr15OYmEhJSQn169dn+vTpdOzYkaSkJLd9Dym8yFkbNmxY9XHXrl3p06cPLVq04KuvvuLWW2+1sDJxZ6NHj64+7tKlC127dqVNmzbMnz+fQYMGWViZ8911111s2LChzveSncyJXqPbb7+9+rhLly5ER0czaNAgtm/fTps2bZxdpiXat29PUlISeXl5fP3119x0000sWLDA6rLOii4bnUJERATe3t5/6b7OyMggKirKoqpcW1hYGO3atSMlJcXqUlxS1ftG76maad26NREREXXufXX33Xfz448/8ttvv9GsWbPqr0dFRVFWVsbBgwePeXxdfB+d6DU6nj59+gDUqfeRn58fsbGx9OjRg0mTJhEfH88rr7zi1u8hhZdT8PPzo0ePHsydO7f6a3a7nblz55KYmGhhZa6rsLCQ7du3Ex0dbXUpLqlVq1ZERUUd857Kz89n2bJlek+dxJ49e8jJyakz7yvDMLj77ruZPn068+bNo1WrVsd8v0ePHvj6+h7zPkpOTiY1NbXOvI9O9RodT1JSEkCdeR8dj91up7S01L3fQ1Z3DLuDL7/80vD39zcmT55sbNq0ybj99tuNsLAwIz093erSXMKDDz5ozJ8/39i5c6fxxx9/GIMHDzYiIiKMzMxMq0uzTEFBgbFmzRpjzZo1BmC8+OKLxpo1a4zdu3cbhmEY//3vf42wsDDj+++/N9atW2eMHDnSaNWqlXHo0CGLK3eek71GBQUFxt///ndjyZIlxs6dO405c+YY3bt3N9q2bWuUlJRYXbpTjB8/3ggNDTXmz59v7N+/v/pWXFxc/Zg77rjDaN68uTFv3jxj5cqVRmJiopGYmGhh1c51qtcoJSXF+Pe//22sXLnS2Llzp/H9998brVu3Nvr3729x5c7z6KOPGgsWLDB27txprFu3znj00UcNm81m/Prrr4ZhuO97SOHlNL322mtG8+bNDT8/P6N3797G0qVLrS7JZVxzzTVGdHS04efnZzRt2tS45pprjJSUFKvLstRvv/1mAH+53XTTTYZhmNOl/+///s9o3Lix4e/vbwwaNMhITk62tmgnO9lrVFxcbFx00UVGZGSk4evra7Ro0cIYN25cnfqF4XivDWB89NFH1Y85dOiQceeddxoNGjQwAgMDjcsuu8zYv3+/dUU72aleo9TUVKN///5GeHi44e/vb8TGxhoPPfSQkZeXZ23hTnTLLbcYLVq0MPz8/IzIyEhj0KBB1cHFMNz3PWQzDMNw3jiPiIiIyNlRz4uIiIi4FYUXERERcSsKLyIiIuJWFF5ERETErSi8iIiIiFtReBERERG3ovAiIiIibkXhRURERNyKwouIiIi4FYUXERERcSsKLyIiIuJWFF5ERETErfw/FwhHwydfpI4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[21,:,6])\n",
    "plt.plot(y[21,:,6])\n",
    "\"\"\"plt.plot(x[20,:,6])\n",
    "plt.plot(x[40,:,6])\n",
    "plt.plot(x[60,:,6])\n",
    "plt.plot(x[80,:,6])\n",
    "plt.plot(x[100,:,6])\n",
    "plt.plot(x[120,:,6])\n",
    "plt.plot(x[140,:,6])\n",
    "plt.plot(x[160,:,6])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_discriminator8=Model_discriminator(50, 50, 35, 35, 20, 10)\\nmodel_discriminator9=Model_discriminator(50, 50, 35, 35, 20, 10)'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model_discriminator(tf.keras.Model):\n",
    "    def __init__(self, units1, units2, units3, units4, units5,units6,  **kwargs):\n",
    "        super(Model_discriminator, self).__init__(**kwargs)\n",
    "\n",
    "        # osc1\n",
    "        self.d1_r = tf.keras.layers.Dense(units1, activation='relu')\n",
    "        self.d1_i = tf.keras.layers.Dense(units1, activation='relu')\n",
    "        self.d1n4_r = TimeDistributed(BatchNormalization())  # Added BatchNorm\n",
    "        self.d1n4_i = TimeDistributed(BatchNormalization())  # Added BatchNorm\n",
    "        self.osc1 = Hopf(units2, num_steps=duration, min_omega=0.1, max_omega=64.1, train_omegas=True)\n",
    "\n",
    "        # osc2\n",
    "        self.d2_r = tf.keras.layers.Dense(units3, activation='relu')\n",
    "        self.d2_i = tf.keras.layers.Dense(units3, activation='relu')\n",
    "        self.d2n4_r = TimeDistributed(BatchNormalization())  # Added BatchNorm\n",
    "        self.d2n4_i = TimeDistributed(BatchNormalization())\n",
    "        self.osc2 = Hopf(units4, num_steps=duration, min_omega=0.1, max_omega=64.1, train_omegas=True)\n",
    "\n",
    "        # New layers beyond osc2\n",
    "        self.d3_r = tf.keras.layers.Dense(units5, activation='tanh')\n",
    "        self.d3_i = tf.keras.layers.Dense(units5, activation='tanh')\n",
    "        #self.d4 = tf.keras.layers.Dense(units7, activation='tanh')\n",
    "        self.d3n4=TimeDistributed(BatchNormalization()) \n",
    "        self.out_dense = tf.keras.layers.Dense(units6, activation='linear')\n",
    "    \n",
    "    def call(self, X):\n",
    "        X1 = tf.identity(X)\n",
    "        out1_r = tf.keras.layers.TimeDistributed(self.d1_r)(X1)\n",
    "        out1_i = tf.keras.layers.TimeDistributed(self.d1_i)(X1)\n",
    "        out1_r=self.d1n4_r(out1_r)\n",
    "        out1_i=self.d1n4_i(out1_i)\n",
    "        z1_r, z1_i = self.osc1(out1_r, out1_i)\n",
    "\n",
    "        out2_r = tf.keras.layers.TimeDistributed(self.d2_r)(z1_r)\n",
    "        out2_i = tf.keras.layers.TimeDistributed(self.d2_i)(z1_i)\n",
    "        out2_r=self.d2n4_r(out2_r)\n",
    "        out2_i=self.d2n4_i(out2_i)\n",
    "        z2_r, z2_i = self.osc2(out2_r, out2_i)\n",
    "\n",
    "        out3_r = tf.keras.layers.TimeDistributed(self.d3_r)(z2_r)\n",
    "        out3_i = tf.keras.layers.TimeDistributed(self.d3_i)(z2_i)\n",
    "        concat_inp = tf.concat([out3_r, out3_i], 2)\n",
    "        concat_inp=self.d3n4(concat_inp)\n",
    "        #out4 = tf.keras.layers.TimeDistributed(self.d4)(concat_inp)\n",
    "        out_final = tf.keras.layers.TimeDistributed(self.out_dense)(concat_inp)\n",
    "\n",
    "        return out_final\n",
    "\n",
    "#model_discriminator=Model_discriminator(7, 7, 4, 4, 3, 2)\n",
    "#model_discriminator=Model_discriminator(30, 30, 20, 20, 15, 10)\n",
    "\n",
    "model_discriminator1=Model_discriminator(50, 50, 35, 35, 20, 10)\n",
    "model_discriminator2=Model_discriminator(50, 50, 35, 35, 20, 10)\n",
    "model_discriminator3=Model_discriminator(50, 50, 35, 35, 20, 10)\n",
    "model_discriminator4=Model_discriminator(50, 50, 35, 35, 20, 10)\n",
    "model_discriminator5=Model_discriminator(50, 50, 35, 35, 20, 10)\n",
    "model_discriminator6=Model_discriminator(50, 50, 35, 35, 20, 10)\n",
    "model_discriminator7=Model_discriminator(50, 50, 35, 35, 20, 10)\n",
    "\"\"\"model_discriminator8=Model_discriminator(50, 50, 35, 35, 20, 10)\n",
    "model_discriminator9=Model_discriminator(50, 50, 35, 35, 20, 10)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:391: UserWarning: `build()` was called on layer 'model_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, units1, units2,units3,units4,units5, **kwargs):\n",
    "\n",
    "        super(Model, self).__init__(**kwargs)\n",
    "\n",
    "        self.d1_r = tf.keras.layers.Dense(units1,activation='relu') # 1st relu layer(real) with neuron=units1\n",
    "        self.d1_i = tf.keras.layers.Dense(units1,activation='relu')# 1st relu layer(imag) with neuron=units1\n",
    "\n",
    "        self.osc1 = Hopf(units2, num_steps=32,min_omega=0.1, max_omega=64.1,train_omegas=True) # 1st osc layer=units2=units1\n",
    "\n",
    "        self.d_r = tf.keras.layers.Dense(units3,activation='tanh') # 1st relu layer(real) with neuron=units1\n",
    "        self.d_i = tf.keras.layers.Dense(units3,activation='tanh')# 1st relu layer(imag) with neuron=units1\n",
    "        \n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(units4, activation='relu') # 2nd relu layer,units3\n",
    "\n",
    "        #self.d2_dr = tf.keras.layers.Dense(units4, activation='linear') #last tanh layer,units5\n",
    "        #self.d2_i = tf.keras.layers.Dense(units4, activation='linear') #last tanh layer,units5\n",
    "        # self.dense2= tf.keras.layers.Dense(units5, activation='relu') # 2nd relu layer,units3\n",
    "\n",
    "        self.out_dense = tf.keras.layers.Dense(units5, activation='linear')# output node, units6, with tanh\n",
    "\n",
    "    def call(self, X):\n",
    "\n",
    "        out1_r = tf.keras.layers.TimeDistributed(self.d1_r)(X)\n",
    "        out1_i = tf.keras.layers.TimeDistributed(self.d1_i)(X)\n",
    "\n",
    "        z1_r, z1_i = self.osc1(out1_r, out1_i)\n",
    "\n",
    "\n",
    "        #concat_inp=tf.concat([z1_r, z1_i],2)\n",
    "        out2_r = tf.keras.layers.TimeDistributed(self.d_r)(z1_r)\n",
    "        out2_i = tf.keras.layers.TimeDistributed(self.d_i)(z1_i)\n",
    "\n",
    "        concat_inp=tf.concat([out2_r,out2_i],2)\n",
    "        # lstmout=self.lstm(concat_inp)\n",
    "        \n",
    "        #out3_r = tf.keras.layers.TimeDistributed(self.d2_r)(out2_r)\n",
    "        #out3_i = tf.keras.layers.TimeDistributed(self.d2_i)(out2_i)\n",
    "        #out3=tf.concat([out3_r,out3_i],2)\n",
    "        denseout=tf.keras.layers.TimeDistributed(self.dense)(concat_inp)\n",
    "        # denseout2=tf.keras.layers.TimeDistributed(self.dense2)(denseout)\n",
    "        out_final = tf.keras.layers.TimeDistributed(self.out_dense)(denseout)\n",
    "        return out_final\n",
    "\n",
    "model_signal_classifier = Model(250,250,128,64,10)\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model_signal_classifier.build(input_shape=(40000,32,14))\n",
    "model_signal_classifier.compile(optimizer, 'mse', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a=model_signal_classifier(squeezed_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights for layer 0 from ../classifier-weights/layer_0_weights_sravan.npy\n",
      "Loaded weights for layer 1 from ../classifier-weights/layer_1_weights_sravan.npy\n",
      "oscillatory layer\n",
      "Loaded weights for layer 3 from ../classifier-weights/layer_3_weights_sravan.npy\n",
      "Loaded weights for layer 4 from ../classifier-weights/layer_4_weights_sravan.npy\n",
      "Loaded weights for layer 5 from ../classifier-weights/layer_5_weights_sravan.npy\n",
      "Loaded weights for layer 6 from ../classifier-weights/layer_6_weights_sravan.npy\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_signal_classifier.layers):\n",
    "    weights_file = f'../classifier-weights/layer_{i}_weights_sravan.npy'\n",
    "    bias_file=f'../classifier-weights/layer_{i}_bias_sravan.npy'  # Adjust if you saved as .h5\n",
    "    try:\n",
    "        weights =[ np.load(bias_file),np.load(weights_file)]\n",
    "        layer.set_weights(weights)\n",
    "        print(f\"Loaded weights for layer {i} from {weights_file}\")\n",
    "    except Exception as e:\n",
    "        model_signal_classifier.osc1.omegas=tf.constant(np.load(\"../classifier-weights/Osc_omegas_sravan.npy\"))\n",
    "        print(f\"oscillatory layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_signals=np.squeeze(y_test_signals,axis=-1)\n",
    "#y_test_signals=np.transpose(y_test_signals,(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 32, 14)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_pred=model_signal_classifier.predict(squeezed_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\n\\n# Generate 1000 random indices\\nnp.random.seed(42)  # for reproducibility\\nrandom_indices = np.random.choice(y_test_pred.shape[0], size=1000, replace=False)\\n\\n# Select the samples using these indices\\nsqueezed_data1_sample = squeezed_data1[random_indices]\\nX_test_compressed_sample =[ X_test_compressed[0][random_indices],X_test_compressed[1][random_indices]]\\ny_test_pred_sample = model_generator.predict(X_test_compressed_sample)\\ny_test_classify_pred=model_signal_classifier.predict(y_test_pred_sample)\\ny_test_classify_sample = y_test_classify[random_indices]\\n\\n# Print shapes to verify\\n\\n# Calculate accuracy for the sampled data\\naccuracy = signal_classifying_accuracy(y_test_classify_sample, y_test_classify_pred)\\nprint(\"Classification accuracy on sampled data:\", accuracy)'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "\n",
    "# Generate 1000 random indices\n",
    "np.random.seed(42)  # for reproducibility\n",
    "random_indices = np.random.choice(y_test_pred.shape[0], size=1000, replace=False)\n",
    "\n",
    "# Select the samples using these indices\n",
    "squeezed_data1_sample = squeezed_data1[random_indices]\n",
    "X_test_compressed_sample =[ X_test_compressed[0][random_indices],X_test_compressed[1][random_indices]]\n",
    "y_test_pred_sample = model_generator.predict(X_test_compressed_sample)\n",
    "y_test_classify_pred=model_signal_classifier.predict(y_test_pred_sample)\n",
    "y_test_classify_sample = y_test_classify[random_indices]\n",
    "\n",
    "# Print shapes to verify\n",
    "\n",
    "# Calculate accuracy for the sampled data\n",
    "accuracy = signal_classifying_accuracy(y_test_classify_sample, y_test_classify_pred)\n",
    "print(\"Classification accuracy on sampled data:\", accuracy)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_test_gen=model_generator.predict(X_test_compressed)\\ny_classify_gen=model_signal_classifier.predict(y_test_gen)'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"y_test_gen=model_generator.predict(X_test_compressed)\n",
    "y_classify_gen=model_signal_classifier.predict(y_test_gen)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_train_gen=model_generator.predict(X_train_compressed)\\ny_classify_gen_train=model_signal_classifier.predict(y_train_gen)\\nsignal_classifying_accuracy(y_train_classify,y_classify_gen_train)'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"y_train_gen=model_generator.predict(X_train_compressed)\n",
    "y_classify_gen_train=model_signal_classifier.predict(y_train_gen)\n",
    "signal_classifying_accuracy(y_train_classify,y_classify_gen_train)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#@tf.function\n",
    "def generator_loss_ramp(y_true,y_pred,y_classify,fake_discriminator,alpha=0.01,beta=0.01,batch=100):\n",
    "    \"\"\"ramp_y=ramp_classifier_output(labels,10)/2\n",
    "    ramp_y=tf.cast(ramp_y,tf.float32)\"\"\"\n",
    "    fake_discriminator=tf.cast(fake_discriminator,tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    A= mse(y_classify, fake_discriminator)\n",
    "    #B= mse(y_true, y_pred)\n",
    "    #B=tf.reduce_mean(y_true)-tf.reduce_mean(y_pred)\n",
    "    B = (tf.math.reduce_mean(y_pred, axis=0) - tf.math.reduce_mean(y_true, axis=0)) ** 2\n",
    "    \n",
    "    l2_loss = (1-alpha)*A+  beta*mse(y_true,y_pred)+alpha*B#+beta*diversity_loss\n",
    "    l2_loss = tf.reduce_mean(l2_loss)\n",
    "    return [A,B,l2_loss]\n",
    "\n",
    "def generator_loss_ramp1(y_true,y_pred,y_classify,fake_discriminators,alpha=0.01,beta=0.01,batch=100):\n",
    "    \"\"\"ramp_y=ramp_classifier_output(labels,10)/2\n",
    "    ramp_y=tf.cast(ramp_y,tf.float32)\"\"\"\n",
    "    fake_discriminators=[tf.cast(fake_discriminators[i],tf.float32) for i in range(4)]\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    A1= mse(y_classify, fake_discriminators[0])\n",
    "    A2= mse(y_classify, fake_discriminators[1])\n",
    "    A3= mse(y_classify, fake_discriminators[2])\n",
    "    A4= mse(y_classify, fake_discriminators[3])\n",
    "    #A5= mse(y_classify, fake_discriminators[4])\n",
    "    #A6= mse(y_classify, fake_discriminators[5])\n",
    "    #A7= mse(y_classify, fake_discriminators[6])\n",
    "    \"\"\"A8= mse(y_classify, fake_discriminators[7])\n",
    "    A9= mse(y_classify, fake_discriminators[8])\"\"\"\n",
    "    #B= mse(y_true, y_pred)\n",
    "    #B=tf.reduce_mean(y_true)-tf.reduce_mean(y_pred)\n",
    "    #A=[A1,A2,A3,A4,A5,A6,A7,A8,A9]\n",
    "    A=[A1,A2,A3,A4]#],A4,A5]\n",
    "    B = (tf.math.reduce_mean(y_pred, axis=0) - tf.math.reduce_mean(y_true, axis=0)) ** 2\n",
    "    l2_loss = (1-alpha)/4*A1+(1-alpha)/4*A2+(1-alpha)/4*A3+(1-alpha)/4*A4+beta*mse(y_true,y_pred)+alpha*B#+beta*diversity_loss\n",
    "    \n",
    "    #l2_loss = (1-alpha)/9*A1+(1-alpha)/9*A2+(1-alpha)/9*A3+(1-alpha)/9*A4+(1-alpha)/9*A5+ (1-alpha)/9*A6+(1-alpha)/9*A7+(1-alpha)/9*A8+ (1-alpha)/9*A9+   beta*mse(y_true,y_pred)+alpha*B#+beta*diversity_loss\n",
    "    l2_loss = tf.reduce_mean(l2_loss)\n",
    "    return [A,B,l2_loss]\n",
    "def generator_loss_ramp2(y_true, y_pred, y_classify, fake_discriminators, alpha=0.01, beta=0.01, batch=100):\n",
    "\n",
    "    # Cast inputs to float32\n",
    "    fake_discriminators = [tf.cast(fake_discriminators[i], tf.float32) for i in range(4)]\n",
    "    #fake_discriminators_out=tf.concat(fake_discriminators,axis=-1)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # Calculate individual losses for each discriminator (per sample in batch)\n",
    "    # Shape of each A_i: [batch_size]\n",
    "    A1 = tf.reduce_mean((y_classify-fake_discriminators[0])**2,axis=0)\n",
    "    A2 = tf.reduce_mean((y_classify-fake_discriminators[1]**2),axis=0)\n",
    "    A3 = tf.reduce_mean((y_classify-fake_discriminators[2])**2,axis=0)\n",
    "    A4 = tf.reduce_mean((y_classify-fake_discriminators[3])**2,axis=0)\n",
    "    #A2 = mse(y_classify, fake_discriminators[1])\n",
    "    #A3 = mse(y_classify, fake_discriminators[2])\n",
    "    #A4 = mse(y_classify, fake_discriminators[3])\n",
    "    #tf.print(A1)\n",
    "    #print(A1.numpy())\n",
    "    stacked_losses = tf.stack([A1, A2, A3, A4], axis=-1)\n",
    "    \n",
    "    # Find the minimum loss for each input in the batch\n",
    "    min_losses = tf.reduce_min(stacked_losses, axis=-1, keepdims=True)\n",
    "    \n",
    "    # Create a mask that gives higher importance to the discriminator with minimum loss\n",
    "    # First identify which loss is minimum for each sample\n",
    "    min_loss_indices = tf.argmin(stacked_losses, axis=-1)\n",
    "    #tf.print(min_loss_indices)\n",
    "    #print(min_loss_indices.numpy())\n",
    "    #print(min_loss_indices.shape)\n",
    "    \n",
    "    # Create importance weights - the classifier with minimum loss gets higher weight\n",
    "    # Convert to one-hot encoding\n",
    "    one_hot_min = tf.one_hot(min_loss_indices, depth=4)\n",
    "    #print(A1*one_hot_min)\n",
    "    #print(one_hot_min.numpy())\n",
    "    #print(one_hot_min.shape)\n",
    "    # Create a weighted importance factor\n",
    "    # Classifiers with minimum loss get weight factor of 0.6, others share the remaining 0.4\n",
    "    # You can adjust these values as needed\n",
    "    importance_factor = 0.7 * one_hot_min + 0.1 * (1 - one_hot_min)\n",
    "    \n",
    "    # Calculate weighted discriminator loss for each sample\n",
    "    # Shape: [batch_size, 5]\n",
    "    #stacked_losses=tf.transpose(stacked_losses, perm=[0, 2, 1])\n",
    "    #  b=importance_factor*y_pred\n",
    "\n",
    "    weighted_disc_losses = (1 - alpha) * importance_factor * stacked_losses\n",
    "    \n",
    "    # Sum across all discriminators for each sample\n",
    "    # Shape: [batch_size]\n",
    "    total_disc_loss = tf.reduce_sum(weighted_disc_losses, axis=0)\n",
    "    total_disc_loss = tf.reduce_mean(total_disc_loss)\n",
    "    # Calculate MSE reconstruction loss\n",
    "    reconstruction_loss = mse(y_true, y_pred)\n",
    "    \n",
    "    # Calculate distribution matching loss (same as original)\n",
    "    distribution_loss = (tf.math.reduce_mean(y_pred, axis=0) - tf.math.reduce_mean(y_true, axis=0)) ** 2\n",
    "    \n",
    "    # Combine all losses\n",
    "    final_loss = total_disc_loss + beta * reconstruction_loss + alpha * distribution_loss\n",
    "    \n",
    "    # Reduce to scalar\n",
    "    final_loss = tf.reduce_mean(final_loss)\n",
    "    \n",
    "    # For monitoring individual losses\n",
    "    A = [tf.reduce_mean(A1), tf.reduce_mean(A2), tf.reduce_mean(A3), tf.reduce_mean(A4)]#, tf.reduce_mean(A5)]\n",
    "    B = tf.reduce_mean(distribution_loss)\n",
    "    \n",
    "    return [A, B, final_loss]\n",
    "def generator_loss_ce(y_true,y_pred,y_classify,fake_discriminator,alpha=0.0,batch=100):\n",
    "    \"\"\"ce_y=cross_entropy_output(labels,10)/2\n",
    "    ce_y=tf.cast(ce_y,tf.float32)\"\"\"\n",
    "    fake_discriminator=tf.cast(fake_discriminator,tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    ce = tf.keras.losses.CategoricalCrossentropy()\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    A= ce(y_classify, fake_discriminator)\n",
    "    B= mse(y_true, y_pred)\n",
    "    l2_loss = (1-alpha)*A+alpha*B\n",
    "    l2_loss = tf.reduce_mean(l2_loss)\n",
    "    return [A,B,l2_loss]\n",
    "\n",
    "def discriminator_loss_ramp(y_true, y_pred,y_classify,y_gen,batch=100):\n",
    "\n",
    "    #concatenated = tf.concat([y_true, y_pred], axis=2)\n",
    "    \"\"\"labels=np.array(labels)\n",
    "    labels_gen=10*np.ones(batch)\"\"\"\n",
    "    #labels_concat=tf.concat([labels,y_gen],axis=2)\n",
    "    #ramp_y=tf.concat([ramp_classifier_output(labels,10)/2,ramp_classifier_output(labels_gen,10)/2],axis=0)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    loss=mse(y_true, y_classify)\n",
    "    loss=tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "def discriminator_loss_ce(y_true, y_pred,y_classify,y_gen,batch=100):\n",
    "\n",
    "    concatenated = tf.concat([y_true, y_pred], axis=2)\n",
    "    #labels=np.array(labels)\n",
    "    #labels_gen=10*np.ones(batch)\n",
    "    labels_concat=tf.concat([y_classify,y_gen],axis=2)\n",
    "    #ce_y=tf.concat([cross_entropy_output_tf(labels,10)/2,cross_entropy_output_tf(labels_gen,10)/2],axis=0)\n",
    "    ce = tf.keras.losses.CategoricalCrossentropy()\n",
    "    loss=ce(concatenated, labels_concat)\n",
    "    loss=tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "discriminator_optimizers = [tf.keras.optimizers.Adam(learning_rate=1e-3) for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(X_img, y_eeg, y_classify,y_labels,y_gen, model_generator, model_discriminator, generator_loss, discriminator_loss, clip_value=1.0,batch_size=100):\n",
    "    \n",
    "    y_labels = tf.cast(y_labels, tf.float32)\n",
    "    y_classify = tf.cast(y_classify, tf.float32)\n",
    "    y_eeg = tf.cast(y_eeg, tf.float32)\n",
    "    y_gen=tf.cast(y_gen,tf.float32)\n",
    "    discriminator_loss=discriminator_loss\n",
    "    generator_loss=generator_loss\n",
    "    # Train the discriminator\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        #generated_data = model_generator(X_img, training=True)  # Generate fake data once here\n",
    "        \n",
    "        # Concatenate real and generated data for discriminator\n",
    "        real_output = model_discriminator(y_eeg, training=True)\n",
    "        #fake_output = model_discriminator(generated_data, training=True)\n",
    "        \n",
    "        # Compute discriminator loss\n",
    "        disc_loss = discriminator_loss(real_output, _,y_classify,y_gen)\n",
    "    \n",
    "    # Compute gradients for discriminator\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, model_discriminator.trainable_variables)\n",
    "    \n",
    "    # Clip the gradients for discriminator\n",
    "    gradients_of_discriminator = [tf.clip_by_value(grad, -clip_value, clip_value) for grad in gradients_of_discriminator]\n",
    "    #print(gradients_of_discriminator)\n",
    "    # Apply clipped gradients for discriminator\n",
    "    discriminator_optimizers[0].apply_gradients(zip(gradients_of_discriminator, model_discriminator.trainable_variables))\n",
    "\n",
    "    # Train the generator\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        # Reuse the same generated data for the generator\n",
    "        generated_data = model_generator(X_img, training=True)\n",
    "        \n",
    "        # Fake output for generator loss\n",
    "        fake_output = model_discriminator(generated_data, training=True)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        # Compute generator loss\n",
    "        [A,B,gen_loss] = generator_loss(y_eeg, generated_data,y_classify, fake_output)\n",
    "    \n",
    "    # Compute gradients for generator\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, model_generator.trainable_variables)\n",
    "    #print(gradients_of_generator)\n",
    "    # Clip the gradients for generator\n",
    "    gradients_of_generator = [tf.clip_by_value(grad, -clip_value, clip_value) for grad in gradients_of_generator]\n",
    "    \n",
    "    # Apply clipped gradients for generator\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, model_generator.trainable_variables))\n",
    "    \n",
    "    # Optionally print losses for monitoring\n",
    "    \n",
    "    #print(A,B,gen_loss,disc_loss)\n",
    "    return A,B,gen_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(X_img, y_eeg, y_classify,y_labels,y_gen, model_generator, model_discriminators,generator_loss, discriminator_loss, clip_value=1.0,batch_size=100):\n",
    "    \n",
    "    y_labels = tf.cast(y_labels, tf.float32)\n",
    "    y_classify = tf.cast(y_classify, tf.float32)\n",
    "    y_eeg = tf.cast(y_eeg, tf.float32)\n",
    "    y_gen=tf.cast(y_gen,tf.float32)\n",
    "    discriminator_loss=discriminator_loss\n",
    "    generator_loss=generator_loss\n",
    "    # Train the discriminator\n",
    "    disc_losses=[]\n",
    "    for i in range(5):\n",
    "        model_discriminator=model_discriminators[i]\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            #generated_data = model_generator(X_img, training=True)  # Generate fake data once here\n",
    "        \n",
    "            # Concatenate real and generated data for discriminator\n",
    "            real_output = model_discriminator(y_eeg, training=True)\n",
    "            #fake_output = model_discriminator(generated_data, training=True)\n",
    "        \n",
    "            # Compute discriminator loss\n",
    "            disc_loss = discriminator_loss(real_output, _,y_classify,y_gen)\n",
    "            disc_losses.append(disc_loss)\n",
    "    \n",
    "        # Compute gradients for discriminator\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, model_discriminator.trainable_variables)\n",
    "    \n",
    "        # Clip the gradients for discriminator\n",
    "        gradients_of_discriminator = [tf.clip_by_value(grad, -clip_value, clip_value) for grad in gradients_of_discriminator]\n",
    "        #print(gradients_of_discriminator)\n",
    "        # Apply clipped gradients for discriminator\n",
    "        discriminator_optimizers[i].apply_gradients(zip(gradients_of_discriminator, model_discriminator.trainable_variables))\n",
    "\n",
    "    # Train the generator\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        # Reuse the same generated data for the generator\n",
    "        generated_data = model_generator(X_img, training=True)\n",
    "        indices=np.random.randint(0,5,4)\n",
    "        # Fake output for generator loss\n",
    "        fake_outputs = [model_discriminators[i](generated_data, training=True) for i in indices]\n",
    "\n",
    "        print(len(fake_outputs))\n",
    "\n",
    "        \n",
    "        # Compute generator loss\n",
    "        [A,B,gen_loss] = generator_loss(y_eeg, generated_data,y_classify, fake_outputs)\n",
    "    \n",
    "    # Compute gradients for generator\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, model_generator.trainable_variables)\n",
    "    #print(gradients_of_generator)\n",
    "    # Clip the gradients for generator\n",
    "    gradients_of_generator = [tf.clip_by_value(grad, -clip_value, clip_value) for grad in gradients_of_generator]\n",
    "    \n",
    "    # Apply clipped gradients for generator\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, model_generator.trainable_variables))\n",
    "    \n",
    "    # Optionally print losses for monitoring\n",
    "    \n",
    "    #print(A,B,gen_loss,disc_loss)\n",
    "    return A,B,gen_loss, disc_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(datasets, X_img, y_eeg, y_classify, y_labels, y_gen, \n",
    "               model_generator, model_discriminators, generator_loss, \n",
    "               discriminator_loss, discriminator_optimizers, generator_optimizer, \n",
    "               clip_value=1.0, batch_size=250):\n",
    "    \n",
    "    # Cast inputs to float32\n",
    "    y_labels = tf.cast(y_labels, tf.float32)\n",
    "    y_classify = tf.cast(y_classify, tf.float32)\n",
    "    y_eeg = tf.cast(y_eeg, tf.float32)\n",
    "    y_gen = tf.cast(y_gen, tf.float32)\n",
    "    \n",
    "    # Sample random batches from the dataset for discriminator training\n",
    "    # We'll use the dataset.take() and dataset.skip() methods with random offsets\n",
    "    dataset_size =160\n",
    "    \n",
    "    # Train each discriminator on different batches\n",
    "    disc_losses = []\n",
    "    for i in range(7):\n",
    "        # Get a random index to sample from dataset\n",
    "        # This is outside the gradient tape so it's okay to use numpy operations\n",
    "        random_index = np.random.randint(0, dataset_size)\n",
    "        \n",
    "        # Skip to random position and take one batch\n",
    "        random_batch = next(iter(datasets.skip(random_index).take(1)))\n",
    "        \n",
    "        X_img1_batch, X_img2_batch, y_eeg_batch, y_classify_batch, y_labels_batch = random_batch\n",
    "        \n",
    "        # Cast batch data to float32\n",
    "        y_eeg_batch = tf.cast(y_eeg_batch, tf.float32)\n",
    "        y_classify_batch = tf.cast(y_classify_batch, tf.float32)\n",
    "        \n",
    "        model_discriminator = model_discriminators[i]\n",
    "        \n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            # Train discriminator on this random batch\n",
    "            real_output = model_discriminator(y_eeg_batch, training=True)\n",
    "            \n",
    "            # Compute discriminator loss\n",
    "            disc_loss = discriminator_loss(real_output, _,y_classify_batch, y_gen)\n",
    "            disc_losses.append(disc_loss)\n",
    "        \n",
    "        # Compute and apply gradients for discriminator\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, model_discriminator.trainable_variables)\n",
    "        gradients_of_discriminator = [tf.clip_by_value(grad, -clip_value, clip_value) \n",
    "                                     for grad in gradients_of_discriminator]\n",
    "        discriminator_optimizers[i].apply_gradients(\n",
    "            zip(gradients_of_discriminator, model_discriminator.trainable_variables))\n",
    "    \n",
    "    # Train the generator using the current batch passed to the function\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        # Generate fake data\n",
    "        generated_data = model_generator(X_img, training=True)\n",
    "        \n",
    "        # Randomly select 3 discriminators\n",
    "        indices = np.random.randint(0, 7, 5)\n",
    "        \n",
    "        # Get outputs from selected discriminators\n",
    "        fake_outputs = [model_discriminators[i](generated_data, training=True) for i in indices]\n",
    "        \n",
    "        # Compute generator loss\n",
    "        [A, B, gen_loss] = generator_loss(y_eeg, generated_data, y_classify, fake_outputs)\n",
    "    \n",
    "    # Compute and apply gradients for generator\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, model_generator.trainable_variables)\n",
    "    gradients_of_generator = [tf.clip_by_value(grad, -clip_value, clip_value) \n",
    "                             for grad in gradients_of_generator]\n",
    "    generator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_generator, model_generator.trainable_variables))\n",
    "    \n",
    "    return A, B, gen_loss, disc_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train(dataset,y_train_gen, epochs, model_generator, model_discriminator, generator_loss, discriminator_loss):\n",
    "    # Initialize losses\n",
    "    disc_loss = 0.0\n",
    "    gen_loss = 0.0\n",
    "    gen_losses=[]\n",
    "    disc_losses=[]\n",
    "    A=0.\n",
    "    B=0.\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        #k=0\n",
    "        # Initialize batch-level losses\n",
    "        for X_img1,X_img2, y_eeg, y_classify,y_labels in dataset:\n",
    "            X_img=[X_img1,X_img2]\n",
    "            A,B,gen_loss, disc_loss = train_step(X_img, y_eeg, y_classify,y_labels,y_train_gen, model_generator, model_discriminator, generator_loss, discriminator_loss,discriminator_optimizers,generator_optimizer)\n",
    "            \n",
    "        print(tf.reduce_mean(A),tf.reduce_mean(B))\n",
    "        print(f\"Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}\")\n",
    "        gen_losses.append(gen_loss)\n",
    "        disc_losses.append(disc_loss)\n",
    "    print(gen_losses)\n",
    "    print(disc_losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_classifying_accuracy(y_true, y_pred):\n",
    "    # Convert tensors to numpy arrays if necessary\n",
    "    y_true_np = np.array(y_true)\n",
    "    y_pred_np = np.array(y_pred)\n",
    "\n",
    "    # Initialize the counter\n",
    "    c = 0\n",
    "\n",
    "    # Vectorized operation to find the indices of the maximum values\n",
    "    y_true_indices = np.argmax(np.sum(y_true_np, axis=1), axis=1)\n",
    "    y_pred_indices = np.argmax(np.sum(y_pred_np, axis=1), axis=1)\n",
    "\n",
    "    # Compare the indices and count the matches\n",
    "    c = np.sum(y_true_indices == y_pred_indices)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = c / len(y_true_np)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal_classifying_accuracy(y_test_classify, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_autoencoder=[0 for i in range(20)]+[1 for i in range(20)]+[2 for i in range(20)]+[3 for i in range(20)]+[4 for i in range(20)]+[5 for i in range(20)]+[6 for i in range(20)]+[7 for i in range(20)]+[8 for i in range(20)]+[9 for i in range(20)]\n",
    "\n",
    "y_autoencoder=np.array(y_autoencoder)\n",
    "y_autoencoder=ramp_classifier_output(y_autoencoder,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train(dataset,y_train_gen, epochs, model_generator, model_discriminators, generator_loss, discriminator_loss):\n",
    "    # Initialize losses\n",
    "    disc_loss = 0.0\n",
    "    gen_loss = 0.0\n",
    "    gen_losses=[]\n",
    "    disc_losses=[]\n",
    "    A=0.\n",
    "    B=0.\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        #k=0\n",
    "        # Initialize batch-level losses\n",
    "        for X_img1,X_img2, y_eeg, y_classify,y_labels in dataset:\n",
    "            X_img=[X_img1,X_img2]\n",
    "            A,B,gen_loss, disc_loss = train_step(dataset,X_img, y_eeg, y_classify,y_labels,y_train_gen, model_generator, model_discriminators, generator_loss, discriminator_loss,discriminator_optimizers,generator_optimizer)\n",
    "            \n",
    "        print(tf.reduce_mean(A),tf.reduce_mean(B))\n",
    "        print(f\"Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}\")\n",
    "        signals_temp=model_generator.predict([X_autoencoder_compressed[0],X_autoencoder_compressed[1]])\n",
    "        ramp_temp=model_signal_classifier.predict(signals_temp)\n",
    "        print(\"Signal Classifying Accuracy: \",signal_classifying_accuracy(y_autoencoder,ramp_temp))\n",
    "        \n",
    "        gen_losses.append(gen_loss)\n",
    "        disc_losses.append(disc_loss)\n",
    "        if epoch%1==0:\n",
    "            model_generator.save_weights(f\"generator_weights5_epochs_{epoch}.weights.h5\")\n",
    "            np.save(f\"generator_omegas5_ce1_epochs_{epoch}.npy\",model_generator.osc3.omegas.numpy())\n",
    "            np.save( f\"generator_omegas5_ce2_epochs_{epoch}.npy\",model_generator.osc4.omegas.numpy())\n",
    "            for i in range(7):\n",
    "                model_discriminators[i].save_weights(f\"discriminator_weights5_ce1_epochs_{epoch}_{i}.weights.h5\")\n",
    "                np.save(f\"discriminator_omegas5_ce1_epochs_{epoch}_{i}.npy\",model_discriminators[i].osc1.omegas.numpy())\n",
    "                np.save(f\"discriminator_omegas5_ce2_epochs_{epoch}_{i}.npy\",model_discriminators[i].osc2.omegas.numpy())\n",
    "    print(gen_losses)\n",
    "    print(disc_losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create dummy dataset for example purposes\n",
    "#dataset = tf.data.Dataset.from_tensor_slices((X_train/255, y_train1,y_train_classify/8)).batch(100)\n",
    "#buffer_size = len(X_train)  # Set buffer size to the length of your training data\n",
    "#dataset = tf.data.Dataset.from_tensor_slices((X_train_compressed, y_train_all, y_train_classify_ce,y_train_labels))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train_compressed[0],X_train_compressed[1], y_train_all, y_train_classify_ce,y_train_labels))\n",
    "shuffled_dataset = dataset.shuffle(40000).batch(250)\n",
    "#shuffled_dataset1 = dataset.shuffle(40000).batch(250)\n",
    "#shuffled_dataset2 = dataset.shuffle(40000).batch(250)\n",
    "#shuffled_dataset3 = dataset.shuffle(40000).batch(250)\n",
    "#shuffled_dataset4 = dataset.shuffle(40000).batch(250)\n",
    "#shuffled_dataset5 = dataset.shuffle(40000).batch(250)\n",
    "#shuffled_datasets=[shuffled_dataset,shuffled_dataset1,shuffled_dataset2,shuffled_dataset3,shuffled_dataset4,shuffled_dataset5]\n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_discriminators=[model_discriminator1,model_discriminator2,model_discriminator3,model_discriminator4,model_discriminator5,model_discriminator6,model_discriminator7]#,model_discriminator8,model_discriminator9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(5):\\n    model_discriminators[i].save_weights(f\"discriminator_weights_ce1_{i}.weights.h5\")\\n    np.save(f\"discriminator_omegas1_ce1_{i}.npy\",model_discriminators[i].osc1.omegas.numpy())\\n    #np.save(f\"discriminator_omegas2_ce1_{i}.npy\",model_discriminators[i].osc2.omegas.numpy())'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch=1\n",
    "model_generator.load_weights(f\"generator_weights5_epochs_{epoch}.weights.h5\")\n",
    "model_generator.osc3.omegas=tf.Variable(np.load(f\"generator_omegas5_ce1_epochs_{epoch}.npy\"))\n",
    "model_generator.osc4.omegas=tf.Variable(np.load(f\"generator_omegas5_ce2_epochs_{epoch}.npy\"))\n",
    "for i in range(7):\n",
    "    model_discriminators[i].load_weights(f\"discriminator_weights5_ce1_epochs_{epoch}_{i}.weights.h5\")\n",
    "    model_discriminators[i].osc1.omegas=tf.Variable(np.load(f\"discriminator_omegas5_ce1_epochs_{epoch}_{i}.npy\"))\n",
    "    model_discriminators[i].osc2.omegas=tf.Variable(np.load(f\"discriminator_omegas5_ce2_epochs_{epoch}_{i}.npy\"))\n",
    "\n",
    "\n",
    "\"\"\"model_generator.load_weights(f\"generator_weights5_ce.weights.h5\")\n",
    "model_generator.osc3.omegas=tf.Variable(np.load(f\"generator_omegas1_ce5.npy\"))\n",
    "model_generator.osc4.omegas=tf.Variable(np.load(f\"generator_omegas2_ce5.npy\"))\n",
    "for i in range(7):\n",
    "    model_discriminators[i].load_weights(f\"discriminator_weights_ce5_{i}.weights.h5\")\n",
    "    model_discriminators[i].osc1.omegas=tf.Variable(np.load(f\"discriminator_omegas5_ce1_{i}.npy\"))\n",
    "    model_discriminators[i].osc2.omegas=tf.Variable(np.load(f\"discriminator_omegas25_ce1_{i}.npy\"))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"model_generator.save_weights()\n",
    "            np.save(,model_generator.osc3.omegas.numpy())\n",
    "            np.save( ,model_generator.osc4.omegas.numpy())\n",
    "            for i in range(5):\n",
    "                model_discriminators[i].save_weights()\n",
    "                np.save(,model_discriminators[i].osc1.omegas.numpy())\n",
    "                np.save(,model_discriminators[i].osc2.omegas.numpy())\n",
    "\"\"\"\n",
    "\"\"\"for i in range(5):\n",
    "    model_discriminators[i].save_weights(f\"discriminator_weights_ce1_{i}.weights.h5\")\n",
    "    np.save(f\"discriminator_omegas1_ce1_{i}.npy\",model_discriminators[i].osc1.omegas.numpy())\n",
    "    #np.save(f\"discriminator_omegas2_ce1_{i}.npy\",model_discriminators[i].osc2.omegas.numpy())\"\"\"\n",
    "#model_discriminator.save_weights(\"discriminator_weights_ce1.weights.h5\")\n",
    "#np.save(\"discriminator_omegas1_ce1.npy\",model_discriminator.osc1.omegas.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "tf.Tensor(0.0716848, shape=(), dtype=float32) tf.Tensor(0.010159, shape=(), dtype=float32)\n",
      "Generator Loss: 0.07857416570186615, Discriminator Loss: [<tf.Tensor: shape=(), dtype=float32, numpy=0.08235384523868561>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08335669338703156>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08457192778587341>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08499796688556671>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08366500586271286>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08323443681001663>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08464471250772476>]\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Signal Classifying Accuracy:  0.69\n",
      "Epoch 2/6\n",
      "tf.Tensor(0.07064722, shape=(), dtype=float32) tf.Tensor(0.010825551, shape=(), dtype=float32)\n",
      "Generator Loss: 0.07806474715471268, Discriminator Loss: [<tf.Tensor: shape=(), dtype=float32, numpy=0.08472104370594025>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08370284736156464>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08599752932786942>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08596857637166977>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08541006594896317>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08364483714103699>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08320122957229614>]\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Signal Classifying Accuracy:  0.75\n",
      "Epoch 3/6\n",
      "tf.Tensor(0.07195427, shape=(), dtype=float32) tf.Tensor(0.010800226, shape=(), dtype=float32)\n",
      "Generator Loss: 0.0879010334610939, Discriminator Loss: [<tf.Tensor: shape=(), dtype=float32, numpy=0.08300446718931198>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0828707367181778>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08439143002033234>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0842973068356514>, <tf.Tensor: shape=(), dtype=float32, numpy=0.082036592066288>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08331715315580368>, <tf.Tensor: shape=(), dtype=float32, numpy=0.08479621261358261>]\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Signal Classifying Accuracy:  0.705\n",
      "Epoch 4/6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshuffled_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_discriminators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_discriminators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator_loss_ramp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscriminator_loss_ramp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, y_train_gen, epochs, model_generator, model_discriminators, generator_loss, discriminator_loss)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_img1,X_img2, y_eeg, y_classify,y_labels \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m     15\u001b[0m     X_img\u001b[38;5;241m=\u001b[39m[X_img1,X_img2]\n\u001b[1;32m---> 16\u001b[0m     A,B,gen_loss, disc_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_eeg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_classify\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_discriminators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdiscriminator_optimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgenerator_optimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39mreduce_mean(A),tf\u001b[38;5;241m.\u001b[39mreduce_mean(B))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerator Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Discriminator Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisc_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(shuffled_dataset,y_train_gen, epochs=6, model_generator=model_generator, model_discriminators=model_discriminators, generator_loss=generator_loss_ramp1, discriminator_loss=discriminator_loss_ramp)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_generator.save_weights(\"generator_weights5_ce.weights.h5\")\n",
    "np.save(\"generator_omegas1_ce5.npy\",model_generator.osc3.omegas.numpy())\n",
    "np.save( \"generator_omegas2_ce5.npy\",model_generator.osc4.omegas.numpy())\n",
    "for i in range(7):\n",
    "    model_discriminators[i].save_weights(f\"discriminator_weights_ce5_{i}.weights.h5\")\n",
    "    np.save(f\"discriminator_omegas5_ce1_{i}.npy\",model_discriminators[i].osc1.omegas.numpy())\n",
    "    np.save(f\"discriminator_omegas25_ce1_{i}.npy\",model_discriminators[i].osc2.omegas.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
